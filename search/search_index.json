{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"efts-io","text":"<p>Ensemble forecast time series</p>"},{"location":"#installation","title":"Installation","text":"<p>Placeholder: August 2024 - the package is in alpha (re)development and not yet up to date on <code>pypi</code></p> <p>With <code>pip</code>:</p> <pre><code>pip install efts-io\n</code></pre> <p>With <code>pipx</code>:</p> <pre><code>python -m pip install --user pipx\npipx install efts-io\n</code></pre>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#001-2024-08-29","title":"0.0.1 - 2024-08-29","text":"<p>Compare with first commit</p>"},{"location":"code-reference/","title":"efts_io code documentation","text":"<p>You are likely to need only to look at the <code>wrapper</code> module to manage your resources.</p>"},{"location":"code-reference/#wrapper-module","title":"Wrapper module","text":""},{"location":"code-reference/#efts_io.wrapper","title":"wrapper","text":"<p>A thin wrapper around xarray for reading and writing Ensemble Forecast Time Series (EFTS) data sets.</p>"},{"location":"code-reference/#efts_io.wrapper.EftsDataSet","title":"EftsDataSet","text":"<pre><code>EftsDataSet(data: Union[str, Dataset])\n</code></pre> <p>Convenience class for access to a Ensemble Forecast Time Series in netCDF file.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def __init__(self, data: Union[str, xr.Dataset]) -&gt; None:\n    \"\"\"Create a new EftsDataSet object.\"\"\"\n    from xarray.coding import times\n\n    self.time_dim = None\n    self.time_zone = \"UTC\"\n    self.time_zone_timestamps = True  # Not sure about https://github.com/csiro-hydroinformatics/efts-io/issues/3\n    self.STATION_DIMNAME = STATION_DIMNAME\n    self.stations_varname = STATION_ID_VARNAME\n    self.LEAD_TIME_DIMNAME = LEAD_TIME_DIMNAME\n    self.ENS_MEMBER_DIMNAME = ENS_MEMBER_DIMNAME\n    self.identifiers_dimensions = []\n    if isinstance(data, str):\n        # work around https://jira.csiro.au/browse/WIRADA-635\n        # lead_time can be a problem with xarray, so do not decode \"times\"\n        x = xr.open_dataset(data, decode_times=False)\n\n        # replace the time and station names coordinates values\n        # TODO This is probably not a long term solution for round-tripping a read/write or vice and versa\n        decod = times.CFDatetimeCoder(use_cftime=True)\n        var = xr.as_variable(x.coords[TIME_DIMNAME])\n        self.time_zone = var.attrs[TIME_STANDARD_ATTR_KEY]\n        time_coords = decod.decode(var, name=TIME_DIMNAME)\n        tz = self.time_zone if self.time_zone_timestamps else None\n        time_coords.values = cftimes_to_pdtstamps(\n            time_coords.values,\n            tz_str=tz,\n        )\n        # stat_coords = x.coords[self.STATION_DIMNAME]\n        station_names = byte_stations_to_str(x[STATION_NAME_VARNAME].values)\n        x = x.assign_coords(\n            {TIME_DIMNAME: time_coords, self.STATION_DIMNAME: station_names},\n        )\n\n        self.data: xr.Dataset = x\n    else:\n        self.data: xr.Dataset = data\n</code></pre>"},{"location":"code-reference/#efts_io.wrapper.EftsDataSet.create_data_variables","title":"create_data_variables","text":"<pre><code>create_data_variables(\n    data_var_def: Dict[str, Dict[str, Any]]\n) -&gt; None\n</code></pre> <p>Create data variables in the data set.</p> <p>var_defs_dict[\"variable_1\"].keys() dict_keys(['name', 'longname', 'units', 'dim_type', 'missval', 'precision', 'attributes'])</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def create_data_variables(self, data_var_def: Dict[str, Dict[str, Any]]) -&gt; None:\n    \"\"\"Create data variables in the data set.\n\n    var_defs_dict[\"variable_1\"].keys()\n    dict_keys(['name', 'longname', 'units', 'dim_type', 'missval', 'precision', 'attributes'])\n    \"\"\"\n    ens_fcast_data_var_def = [x for x in data_var_def.values() if x[\"dim_type\"] == \"4\"]\n    ens_data_var_def = [x for x in data_var_def.values() if x[\"dim_type\"] == \"3\"]\n    point_data_var_def = [x for x in data_var_def.values() if x[\"dim_type\"] == \"2\"]\n\n    four_dims_names = (LEAD_TIME_DIMNAME, STATION_DIMNAME, ENS_MEMBER_DIMNAME, TIME_DIMNAME)\n    three_dims_names = (STATION_DIMNAME, ENS_MEMBER_DIMNAME, TIME_DIMNAME)\n    two_dims_names = (STATION_DIMNAME, TIME_DIMNAME)\n\n    four_dims_shape = tuple(self.data.sizes[dimname] for dimname in four_dims_names)\n    three_dims_shape = tuple(self.data.sizes[dimname] for dimname in three_dims_names)\n    two_dims_shape = tuple(self.data.sizes[dimname] for dimname in two_dims_names)\n    for vardefs, dims_shape, dims_names in [\n        (ens_fcast_data_var_def, four_dims_shape, four_dims_names),\n        (ens_data_var_def, three_dims_shape, three_dims_names),\n        (point_data_var_def, two_dims_shape, two_dims_names),\n    ]:\n        for x in vardefs:\n            varname = x[\"name\"]\n            self.data[varname] = xr.DataArray(\n                name=varname,\n                data=nan_full(dims_shape),\n                coords=self.data.coords,\n                dims=dims_names,\n                attrs={\n                    \"longname\": x[\"longname\"],\n                    UNITS_ATTR_KEY: x[UNITS_ATTR_KEY],\n                    \"missval\": x[\"missval\"],\n                    \"precision\": x[\"precision\"],\n                    **x[\"attributes\"],\n                },\n            )\n</code></pre>"},{"location":"code-reference/#efts_io.wrapper.EftsDataSet.get_all_series","title":"get_all_series","text":"<pre><code>get_all_series(\n    variable_name: str = \"rain_obs\",\n    dimension_id: Optional[str] = None,\n)\n</code></pre> <p>Return a multivariate time series, where each column is the series for one of the identifiers.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def get_all_series(\n    self,\n    variable_name: str = \"rain_obs\",\n    dimension_id: Optional[str] = None,\n):\n    \"\"\"Return a multivariate time series, where each column is the series for one of the identifiers.\"\"\"\n    # Return a multivariate time series, where each column is the series for one of the identifiers (self, e.g. rainfall station identifiers):\n    return self.data[variable_name]\n</code></pre>"},{"location":"code-reference/#efts_io.wrapper.EftsDataSet.get_dim_names","title":"get_dim_names","text":"<pre><code>get_dim_names() -&gt; List[str]\n</code></pre> <p>Gets the name of all dimensions in the data set.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def get_dim_names(self) -&gt; List[str]:\n    \"\"\"Gets the name of all dimensions in the data set.\"\"\"\n    return list(self.data.dims.keys())\n</code></pre>"},{"location":"code-reference/#efts_io.wrapper.EftsDataSet.get_ensemble_for_stations","title":"get_ensemble_for_stations","text":"<pre><code>get_ensemble_for_stations(\n    variable_name: str = \"rain_sim\",\n    identifier: Optional[str] = None,\n    dimension_id: str = ENS_MEMBER_DIMNAME,\n    start_time: Timestamp = None,\n    lead_time_count: Optional[int] = None,\n) -&gt; DataArray\n</code></pre> <p>Not yet implemented.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def get_ensemble_for_stations(\n    self,\n    variable_name: str = \"rain_sim\",\n    identifier: Optional[str] = None,\n    dimension_id: str = ENS_MEMBER_DIMNAME,\n    start_time: pd.Timestamp = None,\n    lead_time_count: Optional[int] = None,\n) -&gt; xr.DataArray:\n    \"\"\"Not yet implemented.\"\"\"\n    # Return a time series, representing a single ensemble member forecast for all stations over the lead time\n    raise NotImplementedError\n</code></pre>"},{"location":"code-reference/#efts_io.wrapper.EftsDataSet.get_ensemble_forecasts","title":"get_ensemble_forecasts","text":"<pre><code>get_ensemble_forecasts(\n    variable_name: str = \"rain_sim\",\n    identifier: Optional[str] = None,\n    dimension_id: Optional[str] = None,\n    start_time: Optional[Timestamp] = None,\n    lead_time_count: Optional[int] = None,\n) -&gt; DataArray\n</code></pre> <p>Gets an ensemble forecast for a variable.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def get_ensemble_forecasts(\n    self,\n    variable_name: str = \"rain_sim\",\n    identifier: Optional[str] = None,\n    dimension_id: Optional[str] = None,\n    start_time: Optional[pd.Timestamp] = None,\n    lead_time_count: Optional[int] = None,\n) -&gt; xr.DataArray:\n    \"\"\"Gets an ensemble forecast for a variable.\"\"\"\n    # Return a time series, ensemble of forecasts over the lead time\n    if dimension_id is None:\n        dimension_id = self.get_stations_varname()\n    td = self.get_time_dim()\n    if start_time is None:\n        start_time = td[0]\n    n_ens = self.get_ensemble_size()\n    index_id = self.index_for_identifier(identifier, dimension_id)\n    check_index_found(index_id, identifier, dimension_id)\n    if lead_time_count is None:\n        lead_time_count = self.get_lead_time_count()\n    indx_time = self.index_for_time(start_time)\n    # float rain_sim[lead_time,station,ens_member,time]\n    ens_data = self.data.get(variable_name)[\n        indx_time,\n        :n_ens,\n        index_id,\n        :lead_time_count,\n    ]\n    # ensData = self.data.get(variable_name), start = [1, index_id, 1, indTime],\n    #     count = c(lead_time_count, 1, nEns, 1), collapse_degen = FALSE)\n    # tu = self.get_lead_time_unit()\n    # if tu == \"days\":\n    #     timeAxis = start_time + pd.Timedelta(ncfile$dim$lead_time$vals)\n    # } else {\n    # timeAxis = start_time + lubridate::dhours(1) * ncfile$dim$lead_time$vals\n    # }\n    # out = xts(x = ensData[, 1, , 1], order.by = timeAxis, tzone = tz(start_time))\n    return ens_data\n</code></pre>"},{"location":"code-reference/#efts_io.wrapper.EftsDataSet.get_ensemble_forecasts_for_station","title":"get_ensemble_forecasts_for_station","text":"<pre><code>get_ensemble_forecasts_for_station(\n    variable_name: str = \"rain_sim\",\n    identifier: Optional[str] = None,\n    dimension_id: Optional[str] = None,\n)\n</code></pre> <p>Return an array, representing all ensemble member forecasts for a single stations over all lead times.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def get_ensemble_forecasts_for_station(\n    self,\n    variable_name: str = \"rain_sim\",\n    identifier: Optional[str] = None,\n    dimension_id: Optional[str] = None,\n):\n    \"\"\"Return an array, representing all ensemble member forecasts for a single stations over all lead times.\"\"\"\n    # Return an array, representing all ensemble member forecasts for a single stations over all lead times\n    if dimension_id is None:\n        dimension_id = self.get_stations_varname()\n    raise NotImplementedError\n</code></pre>"},{"location":"code-reference/#efts_io.wrapper.EftsDataSet.get_ensemble_series","title":"get_ensemble_series","text":"<pre><code>get_ensemble_series(\n    variable_name: str = \"rain_ens\",\n    identifier: Optional[str] = None,\n    dimension_id: Optional[str] = None,\n)\n</code></pre> <p>Return an ensemble of point time series for a station identifier.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def get_ensemble_series(\n    self,\n    variable_name: str = \"rain_ens\",\n    identifier: Optional[str] = None,\n    dimension_id: Optional[str] = None,\n):\n    \"\"\"Return an ensemble of point time series for a station identifier.\"\"\"\n    # Return an ensemble of point time series for a station identifier\n    if dimension_id is None:\n        dimension_id = self.get_stations_varname()\n    raise NotImplementedError\n</code></pre>"},{"location":"code-reference/#efts_io.wrapper.EftsDataSet.get_ensemble_size","title":"get_ensemble_size","text":"<pre><code>get_ensemble_size()\n</code></pre> <p>Return the length of the ensemble size dimension.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def get_ensemble_size(self):\n    \"\"\"Return the length of the ensemble size dimension.\"\"\"\n    return self.data.dims[self.ENS_MEMBER_DIMNAME]\n</code></pre>"},{"location":"code-reference/#efts_io.wrapper.EftsDataSet.get_lead_time_count","title":"get_lead_time_count","text":"<pre><code>get_lead_time_count()\n</code></pre> <p>Length of the lead time dimension.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def get_lead_time_count(self):\n    \"\"\"Length of the lead time dimension.\"\"\"\n    return self.data.dims[self.LEAD_TIME_DIMNAME]\n</code></pre>"},{"location":"code-reference/#efts_io.wrapper.EftsDataSet.get_lead_time_values","title":"get_lead_time_values","text":"<pre><code>get_lead_time_values()\n</code></pre> <p>Return the values of the lead time dimension.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def get_lead_time_values(self):\n    \"\"\"Return the values of the lead time dimension.\"\"\"\n    return self.data[self.LEAD_TIME_DIMNAME].values\n</code></pre>"},{"location":"code-reference/#efts_io.wrapper.EftsDataSet.get_single_series","title":"get_single_series","text":"<pre><code>get_single_series(\n    variable_name: str = \"rain_obs\",\n    identifier: Optional[str] = None,\n    dimension_id: Optional[str] = None,\n)\n</code></pre> <p>Return a single point time series for a station identifier.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def get_single_series(\n    self,\n    variable_name: str = \"rain_obs\",\n    identifier: Optional[str] = None,\n    dimension_id: Optional[str] = None,\n):\n    \"\"\"Return a single point time series for a station identifier.\"\"\"\n    # Return a single point time series for a station identifier. Falls back on def get_all_series if the argument \"identifier\" is missing\n    if dimension_id is None:\n        dimension_id = self.get_stations_varname()\n    return self.data[variable_name].sel({dimension_id: identifier})\n</code></pre>"},{"location":"code-reference/#efts_io.wrapper.EftsDataSet.get_station_count","title":"get_station_count","text":"<pre><code>get_station_count() -&gt; int\n</code></pre> <p>Return the number of stations in the data set.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def get_station_count(self) -&gt; int:\n    \"\"\"Return the number of stations in the data set.\"\"\"\n    self.data.dims[self.STATION_DIMNAME]\n</code></pre>"},{"location":"code-reference/#efts_io.wrapper.EftsDataSet.get_stations_varname","title":"get_stations_varname","text":"<pre><code>get_stations_varname() -&gt; str\n</code></pre> <p>Return the name of the variable that has the station identifiers.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def get_stations_varname(self) -&gt; str:\n    \"\"\"Return the name of the variable that has the station identifiers.\"\"\"\n    # Gets the name of the variable that has the station identifiers\n    # TODO: station is integer normally in STF (Euargh)\n    return STATION_ID_VARNAME\n</code></pre>"},{"location":"code-reference/#efts_io.wrapper.EftsDataSet.get_time_dim","title":"get_time_dim","text":"<pre><code>get_time_dim()\n</code></pre> <p>Return the time dimension variable as a vector of date-time stamps.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def get_time_dim(self):\n    \"\"\"Return the time dimension variable as a vector of date-time stamps.\"\"\"\n    # Gets the time dimension variable as a vector of date-time stamps\n    return self.data.time.values  # but loosing attributes.\n</code></pre>"},{"location":"code-reference/#efts_io.wrapper.EftsDataSet.get_time_unit","title":"get_time_unit","text":"<pre><code>get_time_unit()\n</code></pre> <p>Return the time units of a read time series.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def get_time_unit(self):\n    \"\"\"Return the time units of a read time series.\"\"\"\n    # Gets the time units of a read time series, i.e. \"hours since 2015-10-04 00:00:00 +1030\". Returns the string \"hours\"\n    return \"dummy\"\n</code></pre>"},{"location":"code-reference/#efts_io.wrapper.EftsDataSet.put_lead_time_values","title":"put_lead_time_values","text":"<pre><code>put_lead_time_values(values)\n</code></pre> <p>Set the values of the lead time dimension.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def put_lead_time_values(self, values):\n    \"\"\"Set the values of the lead time dimension.\"\"\"\n    self.data[self.LEAD_TIME_DIMNAME].values = values\n</code></pre>"},{"location":"code-reference/#efts_io.wrapper.EftsDataSet.to_netcdf","title":"to_netcdf","text":"<pre><code>to_netcdf(path: str, version: str = '2.0') -&gt; None\n</code></pre> <p>Write the data set to a netCDF file.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def to_netcdf(self, path: str, version: str = \"2.0\") -&gt; None:\n    \"\"\"Write the data set to a netCDF file.\"\"\"\n    if version != \"2.0\":\n        raise ValueError(\"Only version 2.0 is supported for now\")\n    self.data.to_netcdf(path)\n</code></pre>"},{"location":"code-reference/#efts_io.wrapper.byte_to_string","title":"byte_to_string","text":"<pre><code>byte_to_string(x: Union[int, bytes]) -&gt; str\n</code></pre> <p>Convert a byte to a string.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def byte_to_string(x: Union[int, bytes]) -&gt; str:\n    \"\"\"Convert a byte to a string.\"\"\"\n    if isinstance(x, int):\n        if x &gt; 255 or x &lt; 0:\n            raise ValueError(\"Integer value to bytes: must be in range [0-255]\")\n        x = x.to_bytes(1, \"little\")\n    if not isinstance(x, bytes):\n        raise TypeError(f\"Cannot cast type {type(x)} to bytes\")\n    return str(x, encoding=\"UTF-8\")\n</code></pre>"},{"location":"code_of_conduct/","title":"Contributor Covenant Code of Conduct","text":""},{"location":"code_of_conduct/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation.</p> <p>We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.</p>"},{"location":"code_of_conduct/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment for our community include:</p> <ul> <li>Demonstrating empathy and kindness toward other people</li> <li>Being respectful of differing opinions, viewpoints, and experiences</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Accepting responsibility and apologizing to those affected by our mistakes,   and learning from the experience</li> <li>Focusing on what is best not just for us as individuals, but for the overall   community</li> </ul> <p>Examples of unacceptable behavior include:</p> <ul> <li>The use of sexualized language or imagery, and sexual attention or advances of   any kind</li> <li>Trolling, insulting or derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or email address,   without their explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"code_of_conduct/#enforcement-responsibilities","title":"Enforcement Responsibilities","text":"<p>Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.</p> <p>Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.</p>"},{"location":"code_of_conduct/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>"},{"location":"code_of_conduct/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at jean-michel.perraud@csiro.au. All complaints will be reviewed and investigated promptly and fairly.</p> <p>All community leaders are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"code_of_conduct/#enforcement-guidelines","title":"Enforcement Guidelines","text":"<p>Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:</p>"},{"location":"code_of_conduct/#1-correction","title":"1. Correction","text":"<p>Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.</p> <p>Consequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.</p>"},{"location":"code_of_conduct/#2-warning","title":"2. Warning","text":"<p>Community Impact: A violation through a single incident or series of actions.</p> <p>Consequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.</p>"},{"location":"code_of_conduct/#3-temporary-ban","title":"3. Temporary Ban","text":"<p>Community Impact: A serious violation of community standards, including sustained inappropriate behavior.</p> <p>Consequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.</p>"},{"location":"code_of_conduct/#4-permanent-ban","title":"4. Permanent Ban","text":"<p>Community Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.</p> <p>Consequence: A permanent ban from any sort of public interaction within the community.</p>"},{"location":"code_of_conduct/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html.</p> <p>Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder.</p> <p>For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p>"},{"location":"contributing/#environment-setup","title":"Environment setup","text":"<p>Nothing easier!</p> <p>Fork and clone the repository, then:</p> <pre><code>cd efts-io\nmake setup\n</code></pre> <p>Note</p> <p> If it fails for some reason, you'll need to install uv manually.</p> <p>You can install it with:</p> <pre><code>python3 -m pip install --user pipx\npipx install uv\n</code></pre> <p>Now you can try running <code>make setup</code> again, or simply <code>uv install</code>.</p> <p>You now have the dependencies installed.</p> <p>You can run the application with <code>make run efts [ARGS...]</code>.</p> <p>Run <code>make help</code> to see all the available actions!</p>"},{"location":"contributing/#tasks","title":"Tasks","text":"<p>The entry-point to run commands and tasks is the <code>make</code> Python script, located in the <code>scripts</code> directory. Try running <code>make</code> to show the available commands and tasks. The commands do not need the Python dependencies to be installed, while the tasks do. The cross-platform tasks are written in Python, thanks to duty.</p> <p>If you work in VSCode, we provide an action to configure VSCode for the project.</p>"},{"location":"contributing/#development","title":"Development","text":"<p>As usual:</p> <ol> <li>create a new branch: <code>git switch -c feature-or-bugfix-name</code></li> <li>edit the code and/or the documentation</li> </ol> <p>Before committing:</p> <ol> <li>run <code>make format</code> to auto-format the code</li> <li>run <code>make check</code> to check everything (fix any warning)</li> <li>run <code>make test</code> to run the tests (fix any issue)</li> <li>if you updated the documentation or the project dependencies:<ol> <li>run <code>make docs</code></li> <li>go to http://localhost:8000 and check that everything looks good</li> </ol> </li> <li>follow our commit message convention</li> </ol> <p>If you are unsure about how to fix or ignore a warning, just let the continuous integration fail, and we will help you during review.</p> <p>Don't bother updating the changelog, we will take care of this.</p>"},{"location":"contributing/#commit-message-convention","title":"Commit message convention","text":"<p>Commit messages must follow our convention based on the Angular style or the Karma convention:</p> <pre><code>&lt;type&gt;[(scope)]: Subject\n\n[Body]\n</code></pre> <p>Subject and body must be valid Markdown. Subject must have proper casing (uppercase for first letter if it makes sense), but no dot at the end, and no punctuation in general.</p> <p>Scope and body are optional. Type can be:</p> <ul> <li><code>build</code>: About packaging, building wheels, etc.</li> <li><code>chore</code>: About packaging or repo/files management.</li> <li><code>ci</code>: About Continuous Integration.</li> <li><code>deps</code>: Dependencies update.</li> <li><code>docs</code>: About documentation.</li> <li><code>feat</code>: New feature.</li> <li><code>fix</code>: Bug fix.</li> <li><code>perf</code>: About performance.</li> <li><code>refactor</code>: Changes that are not features or bug fixes.</li> <li><code>style</code>: A change in code style/format.</li> <li><code>tests</code>: About tests.</li> </ul> <p>If you write a body, please add trailers at the end (for example issues and PR references, or co-authors), without relying on GitHub's flavored Markdown:</p> <pre><code>Body.\n\nIssue #10: https://github.com/namespace/project/issues/10\nRelated to PR namespace/other-project#15: https://github.com/namespace/other-project/pull/15\n</code></pre> <p>These \"trailers\" must appear at the end of the body, without any blank lines between them. The trailer title can contain any character except colons <code>:</code>. We expect a full URI for each trailer, not just GitHub autolinks (for example, full GitHub URLs for commits and issues, not the hash or the #issue-number).</p> <p>We do not enforce a line length on commit messages summary and body, but please avoid very long summaries, and very long lines in the body, unless they are part of code blocks that must not be wrapped.</p>"},{"location":"contributing/#pull-requests-guidelines","title":"Pull requests guidelines","text":"<p>Link to any related issue in the Pull Request message.</p> <p>During the review, we recommend using fixups:</p> <pre><code># SHA is the SHA of the commit you want to fix\ngit commit --fixup=SHA\n</code></pre> <p>Once all the changes are approved, you can squash your commits:</p> <pre><code>git rebase -i --autosquash main\n</code></pre> <p>And force-push:</p> <pre><code>git push -f\n</code></pre> <p>If this seems all too complicated, you can push or force-push each new commit, and we will squash them ourselves if needed, before merging.</p>"},{"location":"credits/","title":"Credits","text":""},{"location":"credits/#exec-1--credits","title":"Credits","text":"<p>These projects were used to build efts-io. Thank you!</p> <p>Python | uv | copier-uv</p>"},{"location":"credits/#exec-1--runtime-dependencies","title":"Runtime dependencies","text":"Project Summary Version (accepted) Version (last resolved) License appdirs A small Python module for determining appropriate platform-specific dirs, e.g. a \"user data dir\". <code>&gt;=1.4.4, &gt;=1.4</code> <code>1.4.4</code> MIT certifi Python package for providing Mozilla's CA Bundle. <code>&gt;=2017.4.17</code> <code>2024.8.30</code> MPL-2.0 cf_xarray A convenience wrapper for using CF attributes on xarray objects <code>0.9.4</code> Apache Software License cftime Time-handling functionality from netcdf4-python <code>1.6.4</code> License :: OSI Approved :: MIT License flexcache Saves and loads to the cache a transformed versions of a source object. <code>&gt;=0.3</code> <code>0.3</code> BSD flexparser Parsing made fun ... using typing. <code>&gt;=0.3</code> <code>0.3.1</code> BSD-3-Clause netCDF4 Provides an object-oriented python interface to the netCDF version 4 library <code>&gt;=1.7.1.post2</code> <code>1.7.1.post2</code> MIT numpy Fundamental package for array computing in Python <code>2.1.1</code> BSD License packaging Core utilities for Python packages <code>&gt;=23.1, &gt;=20.5</code> <code>24.1</code> Apache Software License + BSD License pandas Powerful data structures for data analysis, time series, and statistics <code>2.2.2</code> BSD License Pint Physical quantities module <code>&gt;=0.21</code> <code>0.24.3</code> BSD pint-xarray Physical units interface to xarray using Pint <code>0.4</code> Apache-2 python-dateutil Extensions to the standard Python datetime module <code>&gt;=2.8.2, &gt;=2.8.1</code> <code>2.9.0.post0</code> BSD License + Apache Software License pytz World timezone definitions, modern and historical <code>&gt;=2020.1, &gt;=2015.7</code> <code>2024.1</code> MIT six Python 2 and 3 compatibility utilities <code>&gt;=1.5</code> <code>1.16.0</code> MIT typing_extensions Backported and Experimental Type Hints for Python 3.8+ <code>&gt;=4.0</code> <code>4.12.2</code> Python Software Foundation License tzdata Provider of IANA time zone data <code>&gt;=2022.7</code> <code>2024.1</code> Apache-2.0 xarray N-D labeled arrays and datasets in Python <code>2024.7.0</code> Apache-2.0"},{"location":"credits/#exec-1--development-dependencies","title":"Development dependencies","text":"Project Summary Version (accepted) Version (last resolved) License ansimarkup Produce colored terminal text with an xml-like markup <code>~=1.4</code> <code>1.5.0</code> Revised BSD License appdirs A small Python module for determining appropriate platform-specific dirs, e.g. a \"user data dir\". <code>&gt;=1.4.4, &gt;=1.4</code> <code>1.4.4</code> MIT asttokens Annotate AST trees with source code positions <code>&gt;=2.1.0</code> <code>2.4.1</code> Apache 2.0 attrs Classes Without Boilerplate <code>&gt;=22.2.0</code> <code>24.2.0</code> MIT babel Internationalization utilities <code>~=2.10</code> <code>2.16.0</code> BSD-3-Clause beautifulsoup4 Screen-scraping library <code>4.12.3</code> MIT License black The uncompromising code formatter. <code>&gt;=24.4</code> <code>24.8.0</code> MIT bleach An easy safelist-based HTML-sanitizing tool. <code>!=5.0.0</code> <code>6.1.0</code> Apache Software License build A simple, correct Python build frontend <code>&gt;=1.2</code> <code>1.2.1</code> MIT License certifi Python package for providing Mozilla's CA Bundle. <code>&gt;=2017.4.17</code> <code>2024.8.30</code> MPL-2.0 cffi Foreign Function Interface for Python calling C code. <code>1.17.0</code> MIT charset-normalizer The Real First Universal Charset Detector. Open, modern and actively maintained alternative to Chardet. <code>&gt;=2, &lt;4</code> <code>3.3.2</code> MIT click Composable command line interface toolkit <code>&gt;=7.0</code> <code>8.1.7</code> BSD-3-Clause colorama Cross-platform colored terminal text. <code>&gt;=0.4</code> <code>0.4.6</code> BSD License comm Jupyter Python Comm implementation, for usage in ipykernel, xeus-python etc. <code>&gt;=0.1.1</code> <code>0.2.2</code> BSD License coverage Code coverage measurement for Python <code>&gt;=5.2.1</code> <code>7.6.1</code> Apache-2.0 cryptography cryptography is a package which provides cryptographic recipes and primitives to Python developers. <code>&gt;=2.0</code> <code>43.0.1</code> Apache-2.0 OR BSD-3-Clause csscompressor A python port of YUI CSS Compressor <code>&gt;=0.9.5</code> <code>0.9.5</code> BSD debugpy An implementation of the Debug Adapter Protocol for Python <code>&gt;=1.6.5</code> <code>1.8.5</code> MIT decorator Decorators for Humans <code>5.1.1</code> new BSD License defusedxml XML bomb protection for Python stdlib modules <code>0.7.1</code> PSFL docutils Docutils -- Python Documentation Utilities <code>&gt;=0.21.2</code> <code>0.21.2</code> Public Domain + Python Software Foundation License + BSD License + GNU General Public License (GPL) duty A simple task runner. <code>&gt;=1.4</code> <code>1.4.1</code> ISC editables Editable installations <code>&gt;=0.5</code> <code>0.5</code> MIT License execnet execnet: rapid multi-Python deployment <code>&gt;=2.1</code> <code>2.1.1</code> MIT executing Get the currently executing AST node of a frame, and other information <code>&gt;=1.2.0</code> <code>2.1.0</code> MIT failprint Run a command, print its output only if it fails. <code>&gt;=0.11, !=1.0.0</code> <code>1.0.2</code> ISC fastjsonschema Fastest Python implementation of JSON schema <code>&gt;=2.15</code> <code>2.20.0</code> BSD ghp-import Copy your docs directly to the gh-pages branch. <code>&gt;=1.0</code> <code>2.1.0</code> Apache Software License git-changelog Automatic Changelog generator using Jinja2 templates. <code>&gt;=2.5</code> <code>2.5.2</code> ISC gitdb Git Object Database <code>&gt;=4.0.1, &lt;5</code> <code>4.0.11</code> BSD License GitPython GitPython is a Python library used to interact with Git repositories <code>3.1.43</code> BSD-3-Clause griffe Signatures for entire Python programs. Extract the structure, the frame, the skeleton of your project, to generate API documentation or find breaking changes in your API. <code>&gt;=0.49</code> <code>1.2.0</code> ISC htmlmin2 An HTML Minifier <code>&gt;=0.1.13</code> <code>0.1.13</code> BSD idna Internationalized Domain Names in Applications (IDNA) <code>&gt;=2.5, &lt;4</code> <code>3.8</code> BSD License importlib_metadata Read metadata from Python packages <code>&gt;=4.4</code> <code>8.4.0</code> Apache Software License iniconfig brain-dead simple config-ini parsing <code>2.0.0</code> MIT ipykernel IPython Kernel for Jupyter <code>&gt;=6.29.5</code> <code>6.29.5</code> BSD License ipython IPython: Productive Interactive Computing <code>&gt;=7.23.1</code> <code>8.27.0</code> BSD-3-Clause jaraco.classes Utility functions for Python class constructs <code>3.4.0</code> MIT License jaraco.context Useful decorators and context managers <code>6.0.1</code> MIT License jaraco.functools Functools like those found in stdlib <code>4.0.2</code> MIT License jedi An autocompletion tool for Python that can be used for text editors. <code>&gt;=0.16</code> <code>0.19.1</code> MIT jeepney Low-level, pure Python DBus protocol wrapper. <code>&gt;=0.4.2</code> <code>0.8.0</code> MIT License Jinja2 A very fast and expressive template engine. <code>&gt;=2.11.1</code> <code>3.1.4</code> BSD License jsmin JavaScript minifier. <code>&gt;=3.0.1</code> <code>3.0.1</code> MIT License jsonschema An implementation of JSON Schema validation for Python <code>&gt;=2.6</code> <code>4.23.0</code> MIT jsonschema-specifications The JSON Schema meta-schemas and vocabularies, exposed as a Registry <code>&gt;=2023.03.6</code> <code>2023.12.1</code> MIT jupyter_client Jupyter protocol implementation and client libraries <code>&gt;=6.1.12</code> <code>8.6.2</code> BSD License jupyter_core Jupyter core package. A base package on which Jupyter projects rely. <code>&gt;=4.12, !=5.0.*</code> <code>5.7.2</code> BSD License jupyterlab_pygments Pygments theme using JupyterLab CSS variables <code>0.3.0</code> BSD License jupytext Jupyter notebooks as Markdown documents, Julia, Python or R scripts <code>&gt;=1.16.4</code> <code>1.16.4</code> MIT License keyring Store and access your passwords safely. <code>&gt;=15.1</code> <code>25.3.0</code> MIT License Markdown Python implementation of John Gruber's Markdown. <code>&gt;=3.3.6</code> <code>3.7</code> BSD License markdown-callouts Markdown extension: a classier syntax for admonitions <code>&gt;=0.4</code> <code>0.4.0</code> MIT markdown-exec Utilities to execute code blocks in Markdown files. <code>&gt;=1.8</code> <code>1.9.3</code> ISC markdown-it-py Python port of markdown-it. Markdown parsing, done right! <code>&gt;=1.0</code> <code>3.0.0</code> MIT License MarkupSafe Safely add untrusted strings to HTML/XML markup. <code>&gt;=2.0.1</code> <code>2.1.5</code> BSD-3-Clause matplotlib-inline Inline Matplotlib backend for Jupyter <code>&gt;=0.1</code> <code>0.1.7</code> BSD License mdit-py-plugins Collection of plugins for markdown-it-py <code>0.4.1</code> MIT License mdurl Markdown URL utilities <code>~=0.1</code> <code>0.1.2</code> MIT License mergedeep A deep merge function for \ud83d\udc0d. <code>&gt;=1.3.4</code> <code>1.3.4</code> MIT License mistune A sane and fast Markdown parser with useful plugins and renderers <code>&gt;=2.0.3, &lt;4</code> <code>3.0.2</code> BSD-3-Clause mkdocs Project documentation with Markdown. <code>&gt;=1.6</code> <code>1.6.1</code> BSD-2-Clause mkdocs-autorefs Automatically link across pages in MkDocs. <code>&gt;=1.2</code> <code>1.2.0</code> ISC mkdocs-coverage MkDocs plugin to integrate your coverage HTML report into your site. <code>&gt;=1.0</code> <code>1.1.0</code> ISC mkdocs-gen-files MkDocs plugin to programmatically generate documentation pages during the build <code>&gt;=0.5</code> <code>0.5.0</code> MIT mkdocs-get-deps MkDocs extension that lists all dependencies according to a mkdocs.yml file <code>&gt;=0.2.0</code> <code>0.2.0</code> MIT mkdocs-git-committers-plugin-2 An MkDocs plugin to create a list of contributors on the page. The git-committers plugin will seed the template context with a list of GitHub or GitLab committers and other useful GIT info such as last modified date <code>&gt;=2.3</code> <code>2.3.0</code> MIT mkdocs-jupyter Use Jupyter in mkdocs websites <code>&gt;=0.24.8</code> <code>0.24.8</code> Apache-2.0 mkdocs-literate-nav MkDocs plugin to specify the navigation in Markdown instead of YAML <code>&gt;=0.6</code> <code>0.6.1</code> MIT mkdocs-material Documentation that simply works <code>&gt;=9.5</code> <code>9.5.34</code> MIT mkdocs-material-extensions Extension pack for Python Markdown and MkDocs Material. <code>~=1.3</code> <code>1.3.1</code> MIT mkdocs-minify-plugin An MkDocs plugin to minify HTML, JS or CSS files prior to being written to disk <code>&gt;=0.8</code> <code>0.8.0</code> MIT mkdocstrings Automatic documentation from sources, for MkDocs. <code>&gt;=0.25</code> <code>0.26.0</code> ISC mkdocstrings-python A Python handler for mkdocstrings. <code>&gt;=0.5.2</code> <code>1.11.1</code> ISC more-itertools More routines for operating on iterables, beyond itertools <code>10.4.0</code> MIT License mypy Optional static typing for Python <code>&gt;=1.10</code> <code>1.11.2</code> MIT mypy-extensions Type system extensions for programs checked with the mypy type checker. <code>&gt;=0.4.3</code> <code>1.0.0</code> MIT License nbclient A client library for executing notebooks. Formerly nbconvert's ExecutePreprocessor. <code>&gt;=0.5.0</code> <code>0.10.0</code> BSD License nbconvert Converting Jupyter Notebooks (.ipynb files) to other formats.  Output formats include asciidoc, html, latex, markdown, pdf, py, rst, script.  nbconvert can be used both as a Python library (<code>import nbconvert</code>) or as a command line tool (invoked as <code>jupyter nbconvert ...</code>). <code>&gt;=7.2.9, &lt;8</code> <code>7.16.4</code> BSD License nbformat The Jupyter Notebook format <code>5.10.4</code> BSD License nbstripout Strips outputs from Jupyter and IPython notebooks <code>&gt;=0.7.1</code> <code>0.7.1</code> License :: OSI Approved :: MIT License nest-asyncio Patch asyncio to allow nested event loops <code>1.6.0</code> BSD nh3 Python bindings to the ammonia HTML sanitization library. <code>&gt;=0.2.14</code> <code>0.2.18</code> MIT packaging Core utilities for Python packages <code>&gt;=23.1, &gt;=20.5</code> <code>24.1</code> Apache Software License + BSD License paginate Divides large result sets into pages for easier browsing <code>~=0.5</code> <code>0.5.7</code> MIT pandocfilters Utilities for writing pandoc filters in python <code>&gt;=1.4.1</code> <code>1.5.1</code> BSD-3-Clause parso A Python Parser <code>&gt;=0.8.3, &lt;0.9.0</code> <code>0.8.4</code> MIT pathspec Utility library for gitignore style pattern matching of file paths. <code>&gt;=0.11.1</code> <code>0.12.1</code> Mozilla Public License 2.0 (MPL 2.0) pexpect Pexpect allows easy control of interactive console applications. <code>&gt;4.3</code> <code>4.9.0</code> ISC license pkginfo Query metadata from sdists / bdists / installed packages. <code>&gt;=1.8.1</code> <code>1.10.0</code> MIT platformdirs A small Python package for determining appropriate platform-specific dirs, e.g. a <code>user data dir</code>. <code>&gt;=2</code> <code>4.2.2</code> MIT pluggy plugin and hook calling mechanisms for python <code>&gt;=1.5, &lt;2</code> <code>1.5.0</code> MIT prompt_toolkit Library for building powerful interactive command lines in Python <code>&gt;=3.0.41, &lt;3.1.0</code> <code>3.0.47</code> BSD License psutil Cross-platform lib for process and system monitoring in Python. <code>6.0.0</code> BSD-3-Clause ptyprocess Run a subprocess in a pseudo terminal <code>~=0.6</code> <code>0.7.0</code> ISC License (ISCL) pure_eval Safely evaluate AST nodes without side effects <code>0.2.3</code> MIT pycparser C parser in Python <code>2.22</code> BSD-3-Clause Pygments Pygments is a syntax highlighting package written in Python. <code>~=2.16</code> <code>2.18.0</code> BSD-2-Clause pymdown-extensions Extension pack for Python Markdown. <code>~=10.2</code> <code>10.9</code> MIT pyproject_hooks Wrappers to call pyproject.toml-based build backend hooks. <code>1.1.0</code> MIT License pytest pytest: simple powerful testing with Python <code>&gt;=8.2</code> <code>8.3.2</code> MIT pytest-cov Pytest plugin for measuring coverage. <code>&gt;=5.0</code> <code>5.0.0</code> MIT pytest-randomly Pytest plugin to randomly order tests and control random.seed. <code>&gt;=3.15</code> <code>3.15.0</code> MIT pytest-xdist pytest xdist plugin for distributed testing, most importantly across multiple CPUs <code>&gt;=3.6</code> <code>3.6.1</code> MIT License python-dateutil Extensions to the standard Python datetime module <code>&gt;=2.8.2, &gt;=2.8.1</code> <code>2.9.0.post0</code> BSD License + Apache Software License pytz World timezone definitions, modern and historical <code>&gt;=2020.1, &gt;=2015.7</code> <code>2024.1</code> MIT PyYAML YAML parser and emitter for Python <code>&gt;=5.1</code> <code>6.0.2</code> MIT pyyaml_env_tag A custom YAML tag for referencing environment variables in YAML files. <code>&gt;=0.1</code> <code>0.1</code> MIT License pyzmq Python bindings for 0MQ <code>&gt;=24</code> <code>26.2.0</code> BSD License readme_renderer readme_renderer is a library for rendering readme descriptions for Warehouse <code>&gt;=35.0</code> <code>44.0</code> Apache License, Version 2.0 referencing JSON Referencing + Python <code>&gt;=0.28.4</code> <code>0.35.1</code> MIT License regex Alternative regular expression module, to replace re. <code>&gt;=2022.4</code> <code>2024.7.24</code> Apache Software License requests Python HTTP for Humans. <code>~=2.26</code> <code>2.32.3</code> Apache-2.0 requests-toolbelt A utility belt for advanced users of python-requests <code>&gt;=0.8.0, !=0.9.0</code> <code>1.0.0</code> Apache 2.0 rfc3986 Validating URI References per RFC 3986 <code>&gt;=1.4.0</code> <code>2.0.0</code> Apache 2.0 rich Render rich text, tables, progress bars, syntax highlighting, markdown and more to the terminal <code>&gt;=12.0.0</code> <code>13.8.0</code> MIT rpds-py Python bindings to Rust's persistent data structures (rpds) <code>&gt;=0.7.1</code> <code>0.20.0</code> MIT ruff An extremely fast Python linter and code formatter, written in Rust. <code>&gt;=0.4</code> <code>0.6.3</code> MIT SecretStorage Python bindings to FreeDesktop.org Secret Service API <code>&gt;=3.2</code> <code>3.3.3</code> BSD 3-Clause License semver Python helper for Semantic Versioning (https://semver.org) <code>&gt;=2.13</code> <code>3.0.2</code> BSD six Python 2 and 3 compatibility utilities <code>&gt;=1.5</code> <code>1.16.0</code> MIT smmap A pure Python implementation of a sliding window memory map manager <code>&gt;=3.0.1, &lt;6</code> <code>5.0.1</code> BSD soupsieve A modern CSS selector implementation for Beautiful Soup. <code>&gt;1.2</code> <code>2.6</code> MIT stack-data Extract data from python stack frames and tracebacks for informative displays <code>0.6.3</code> MIT tinycss2 A tiny CSS parser <code>1.3.0</code> BSD License tornado Tornado is a Python web framework and asynchronous networking library, originally developed at FriendFeed. <code>&gt;=6.1</code> <code>6.4.1</code> Apache-2.0 traitlets Traitlets Python configuration system <code>&gt;=5.4.0</code> <code>5.14.3</code> BSD License twine Collection of utilities for publishing packages on PyPI <code>&gt;=5.0</code> <code>5.1.1</code> Apache Software License types-Markdown Typing stubs for Markdown <code>&gt;=3.6</code> <code>3.7.0.20240822</code> Apache-2.0 types-PyYAML Typing stubs for PyYAML <code>&gt;=6.0</code> <code>6.0.12.20240808</code> Apache-2.0 typing_extensions Backported and Experimental Type Hints for Python 3.8+ <code>&gt;=4.0</code> <code>4.12.2</code> Python Software Foundation License urllib3 HTTP library with thread-safe connection pooling, file post, and more. <code>&gt;=1.26.0</code> <code>2.2.2</code> MIT License watchdog Filesystem events monitoring <code>&gt;=2.0</code> <code>5.0.2</code> Apache-2.0 wcwidth Measures the displayed width of unicode strings in a terminal <code>0.2.13</code> MIT webencodings Character encoding aliases for legacy web content <code>&gt;=0.4</code> <code>0.5.1</code> BSD zipp Backport of pathlib-compatible object wrapper for zip files <code>&gt;=0.5</code> <code>3.20.1</code> MIT License"},{"location":"license/","title":"License","text":"<pre><code>The Clear BSD License\n\nCopyright (c) 2024 CSIRO\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted (subject to the limitations in the disclaimer\nbelow) provided that the following conditions are met:\n\n     * Redistributions of source code must retain the above copyright notice,\n     this list of conditions and the following disclaimer.\n\n     * Redistributions in binary form must reproduce the above copyright\n     notice, this list of conditions and the following disclaimer in the\n     documentation and/or other materials provided with the distribution.\n\n     * Neither the name of the copyright holder nor the names of its\n     contributors may be used to endorse or promote products derived from this\n     software without specific prior written permission.\n\nNO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED BY\nTHIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND\nCONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\nPARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR\nCONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\nEXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\nPROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR\nBUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER\nIN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\nARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\nPOSSIBILITY OF SUCH DAMAGE.\n</code></pre>"},{"location":"tech_notes/","title":"tech notes","text":"<p>https://pawamoy.github.io/copier-uv/work/</p> <p>echo $PYTHON_VERSIONS 3.12</p> <p>These are notes for the package maintainer(s). Most users can ignore them.</p> <p>Note to self: as of Jan 2019 also using github_jm\\didactique\\doc\\know_how.md to log the exploratory and release processes around <code>refcount</code></p>"},{"location":"tech_notes/#release-steps","title":"Release steps","text":"<ul> <li>all UT pass</li> <li>Merge new features/fixes to devel branch.</li> <li>version.py updated</li> <li>check readme is up to date</li> </ul>"},{"location":"tech_notes/#code","title":"Code","text":"<pre><code>cd ${HOME}/src/efts-python/efts-io\n</code></pre> <pre><code>source ${HOME}/anaconda3/bin/activate\n#my_env_name=efts\nmy_env_name=pt\n</code></pre> <pre><code>conda create --name ${my_env_name} python=3.9\nconda activate ${my_env_name}\nconda install -c conda-forge wheel twine six pytest \n</code></pre> <pre><code>conda activate ${my_env_name}\ncd ${HOME}/src/efts-python/efts-io\nmkdir -p dist\nrm dist/*\npython3 setup.py sdist bdist_wheel\nrm dist/*.tar\n</code></pre> <p>Importantly to not end up with incorrect display of the readme:</p> <pre><code>twine check dist/*\n</code></pre> <pre><code>twine upload --repository-url https://test.pypi.org/legacy/ dist/*\n</code></pre> <p>Then and only then:</p> <pre><code>twine upload dist/*\n</code></pre>"},{"location":"tech_notes/#documentation","title":"Documentation","text":"<p>2021-01 Exploring options for putting this on readthedoc. I used in the past sphinx with napoleon extensions to document ela. This was a trial run. Did something more substantial for an internal project (WAA).</p> <p>Starting afresh with this, reading the RTD guides. Introduces mkdocs. Notice this blog on mkdocs-material which seems like the new cool kid on the block.</p> <p>Unclear from RTD where to create a new mkdocs project (supposed to be in the root of the python package?) not sure. for now:</p> <pre><code>cd doc\nmkdir mkd\ncd mkd/\nmkdocs new .\n</code></pre> <p><code>mamba install -c conda-forge mkdocs-material mkdocstrings</code> <code>mamba install -c conda-forge mkdocs-material-extensions</code></p>"},{"location":"tech_notes/#troubleshooting","title":"Troubleshooting","text":"<pre><code>pandoc -f markdown -t rst README.md  &gt; README.rst\n</code></pre> <p>Can view with the <code>retext</code> program (did not find VScode RST extensions working, or giving out blank output if not, perhaps)</p> <pre><code>python setup.py check --restructuredtext\n</code></pre>"},{"location":"nb/basic_usage/","title":"Basic use","text":"In\u00a0[2]: Copied! <pre>import pandas as pd\nimport numpy as np\n</pre> import pandas as pd import numpy as np In\u00a0[3]: Copied! <pre>from efts_io import wrapper as w\n</pre> from efts_io import wrapper as w In\u00a0[4]: Copied! <pre>issue_times = pd.date_range(\"2010-01-01\", periods=31, freq=\"D\")\nstation_ids = [\"410088\",\"410776\"]\nlead_times = np.arange(start=1, stop=4, step=1)\nlead_time_tstep = \"hours\"\nensemble_size = 10\nstation_names= [\"GOODRADIGBEE B/BELLA\", \"Licking Hole Ck\"]# None\nnc_attributes = None\nlatitudes = None\nlongitudes = None\nareas = None\n\nd = w.xr_efts(\n    issue_times,\n    station_ids,\n    lead_times,\n    lead_time_tstep,\n    ensemble_size,\n    station_names,\n    latitudes,\n    longitudes,\n    areas,\n    nc_attributes,\n)\n</pre> issue_times = pd.date_range(\"2010-01-01\", periods=31, freq=\"D\") station_ids = [\"410088\",\"410776\"] lead_times = np.arange(start=1, stop=4, step=1) lead_time_tstep = \"hours\" ensemble_size = 10 station_names= [\"GOODRADIGBEE B/BELLA\", \"Licking Hole Ck\"]# None nc_attributes = None latitudes = None longitudes = None areas = None  d = w.xr_efts(     issue_times,     station_ids,     lead_times,     lead_time_tstep,     ensemble_size,     station_names,     latitudes,     longitudes,     areas,     nc_attributes, )  <p>Let us have a look at the created Dataset:</p> In\u00a0[5]: Copied! <pre>d\n</pre> d Out[5]: <pre>&lt;xarray.Dataset&gt; Size: 608B\nDimensions:       (station_id: 2, time: 31, ens_member: 10, lead_time: 3)\nCoordinates:\n  * time          (time) datetime64[ns] 248B 2010-01-01 ... 2010-01-31\n  * station_id    (station_id) &lt;U6 48B '410088' '410776'\n  * ens_member    (ens_member) int64 80B 1 2 3 4 5 6 7 8 9 10\n  * lead_time     (lead_time) int64 24B 1 2 3\nData variables:\n    station_name  (station_id) &lt;U20 160B 'GOODRADIGBEE B/BELLA' 'Licking Hole...\n    lat           (station_id) float64 16B nan nan\n    lon           (station_id) float64 16B nan nan\n    area          (station_id) float64 16B nan nan\nAttributes:\n    title:                   not provided\n    institution:             not provided\n    catchment:               not provided\n    source:                  not provided\n    comment:                 not provided\n    STF_convention_version:  2.0\n    STF_nc_spec:             https://github.com/csiro-hydroinformatics/efts/b...</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>station_id: 2</li><li>time: 31</li><li>ens_member: 10</li><li>lead_time: 3</li></ul></li><li>Coordinates: (4)<ul><li>time(time)datetime64[ns]2010-01-01 ... 2010-01-31standard_name :timelong_name :timeaxis :t<pre>array(['2010-01-01T00:00:00.000000000', '2010-01-02T00:00:00.000000000',\n       '2010-01-03T00:00:00.000000000', '2010-01-04T00:00:00.000000000',\n       '2010-01-05T00:00:00.000000000', '2010-01-06T00:00:00.000000000',\n       '2010-01-07T00:00:00.000000000', '2010-01-08T00:00:00.000000000',\n       '2010-01-09T00:00:00.000000000', '2010-01-10T00:00:00.000000000',\n       '2010-01-11T00:00:00.000000000', '2010-01-12T00:00:00.000000000',\n       '2010-01-13T00:00:00.000000000', '2010-01-14T00:00:00.000000000',\n       '2010-01-15T00:00:00.000000000', '2010-01-16T00:00:00.000000000',\n       '2010-01-17T00:00:00.000000000', '2010-01-18T00:00:00.000000000',\n       '2010-01-19T00:00:00.000000000', '2010-01-20T00:00:00.000000000',\n       '2010-01-21T00:00:00.000000000', '2010-01-22T00:00:00.000000000',\n       '2010-01-23T00:00:00.000000000', '2010-01-24T00:00:00.000000000',\n       '2010-01-25T00:00:00.000000000', '2010-01-26T00:00:00.000000000',\n       '2010-01-27T00:00:00.000000000', '2010-01-28T00:00:00.000000000',\n       '2010-01-29T00:00:00.000000000', '2010-01-30T00:00:00.000000000',\n       '2010-01-31T00:00:00.000000000'], dtype='datetime64[ns]')</pre></li><li>station_id(station_id)&lt;U6'410088' '410776'long_name :station or node identification code<pre>array(['410088', '410776'], dtype='&lt;U6')</pre></li><li>ens_member(ens_member)int641 2 3 4 5 6 7 8 9 10standard_name :ens_memberlong_name :ensemble memberunits :member idaxis :u<pre>array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])</pre></li><li>lead_time(lead_time)int641 2 3standard_name :lead timelong_name :forecast lead timeaxis :vunits :hours since time<pre>array([1, 2, 3])</pre></li></ul></li><li>Data variables: (4)<ul><li>station_name(station_id)&lt;U20'GOODRADIGBEE B/BELLA' 'Licking ...long_name :station or node name<pre>array(['GOODRADIGBEE B/BELLA', 'Licking Hole Ck'], dtype='&lt;U20')</pre></li><li>lat(station_id)float64nan nanlong_name :latitudeunits :degrees_northaxis :y<pre>array([nan, nan])</pre></li><li>lon(station_id)float64nan nanlong_name :longitudeunits :degrees_eastaxis :x<pre>array([nan, nan])</pre></li><li>area(station_id)float64nan nanlong_name :station areaunits :km^2standard_name :area<pre>array([nan, nan])</pre></li></ul></li><li>Indexes: (4)<ul><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2010-01-01', '2010-01-02', '2010-01-03', '2010-01-04',\n               '2010-01-05', '2010-01-06', '2010-01-07', '2010-01-08',\n               '2010-01-09', '2010-01-10', '2010-01-11', '2010-01-12',\n               '2010-01-13', '2010-01-14', '2010-01-15', '2010-01-16',\n               '2010-01-17', '2010-01-18', '2010-01-19', '2010-01-20',\n               '2010-01-21', '2010-01-22', '2010-01-23', '2010-01-24',\n               '2010-01-25', '2010-01-26', '2010-01-27', '2010-01-28',\n               '2010-01-29', '2010-01-30', '2010-01-31'],\n              dtype='datetime64[ns]', name='time', freq='D'))</pre></li><li>station_idPandasIndex<pre>PandasIndex(Index(['410088', '410776'], dtype='object', name='station_id'))</pre></li><li>ens_memberPandasIndex<pre>PandasIndex(Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype='int64', name='ens_member'))</pre></li><li>lead_timePandasIndex<pre>PandasIndex(Index([1, 2, 3], dtype='int64', name='lead_time'))</pre></li></ul></li><li>Attributes: (7)title :not providedinstitution :not providedcatchment :not providedsource :not providedcomment :not providedSTF_convention_version :2.0STF_nc_spec :https://github.com/csiro-hydroinformatics/efts/blob/107c553045a37e6ef36b2eababf6a299e7883d50/docs/netcdf_for_water_forecasting.md</li></ul> <p>We did not provide custom global attributes to the functions. Defaults were created.</p> <p>Note that while the intent is that the on-disk netCDF file created later will comply with the STF specs, but this is debatable whether the \"in memory\" data set just created should advertise the STF related attributes like <code>STF_convention_version</code>. If saved by the user with <code>to_netcdf</code> rather than via <code>efts-io</code>, it is a tad confusing.</p> In\u00a0[6]: Copied! <pre>d.attrs\n</pre> d.attrs Out[6]: <pre>{'title': 'not provided',\n 'institution': 'not provided',\n 'catchment': 'not provided',\n 'source': 'not provided',\n 'comment': 'not provided',\n 'STF_convention_version': '2.0',\n 'STF_nc_spec': 'https://github.com/csiro-hydroinformatics/efts/blob/107c553045a37e6ef36b2eababf6a299e7883d50/docs/netcdf_for_water_forecasting.md'}</pre> In\u00a0[7]: Copied! <pre>d.time.attrs\n</pre> d.time.attrs Out[7]: <pre>{'standard_name': 'time', 'long_name': 'time', 'axis': 't'}</pre> In\u00a0[14]: Copied! <pre>import cf_xarray as cfx\n</pre> import cf_xarray as cfx In\u00a0[15]: Copied! <pre>import xarray as xr\nxr.set_options(display_expand_data=False)\nxr.set_options(keep_attrs=True)\n</pre> import xarray as xr xr.set_options(display_expand_data=False) xr.set_options(keep_attrs=True) Out[15]: <pre>&lt;xarray.core.options.set_options at 0x7f7d981caa20&gt;</pre> In\u00a0[16]: Copied! <pre>d.lon\n</pre> d.lon Out[16]: <pre>&lt;xarray.DataArray 'lon' (station_id: 2)&gt; Size: 16B\nnan nan\nCoordinates:\n  * station_id  (station_id) &lt;U6 48B '410088' '410776'\nAttributes:\n    long_name:  longitude\n    units:      degrees_east\n    axis:       x</pre>xarray.DataArray'lon'<ul><li>station_id: 2</li></ul><ul><li>nan nan<pre>array([nan, nan])</pre></li><li>Coordinates: (1)<ul><li>station_id(station_id)&lt;U6'410088' '410776'long_name :station or node identification code<pre>array(['410088', '410776'], dtype='&lt;U6')</pre></li></ul></li><li>Indexes: (1)<ul><li>station_idPandasIndex<pre>PandasIndex(Index(['410088', '410776'], dtype='object', name='station_id'))</pre></li></ul></li><li>Attributes: (3)long_name :longitudeunits :degrees_eastaxis :x</li></ul> In\u00a0[17]: Copied! <pre>d.cf\n</pre> d.cf Out[17]: <pre>Coordinates:\n             CF Axes: * T: ['time']\n                        X, Y, Z: n/a\n\n      CF Coordinates: * time: ['time']\n                        longitude, latitude, vertical: n/a\n\n       Cell Measures:   area, volume: n/a\n\n      Standard Names: * ens_member: ['ens_member']\n                      * lead time: ['lead_time']\n                      * time: ['time']\n\n              Bounds:   n/a\n\n       Grid Mappings:   n/a\n\nData Variables:\n       Cell Measures:   area, volume: n/a\n\n      Standard Names:   area: ['area']\n\n              Bounds:   n/a\n\n       Grid Mappings:   n/a</pre> In\u00a0[12]: Copied! <pre>d.cf[\"lon\"]\n</pre> d.cf[\"lon\"] Out[12]: <pre>&lt;xarray.DataArray 'lon' (station_id: 2)&gt; Size: 16B\nnan nan\nCoordinates:\n  * station_id  (station_id) &lt;U6 48B '410088' '410776'\nAttributes:\n    long_name:  longitude\n    units:      degrees_east\n    axis:       x</pre>xarray.DataArray'lon'<ul><li>station_id: 2</li></ul><ul><li>nan nan<pre>array([nan, nan])</pre></li><li>Coordinates: (1)<ul><li>station_id(station_id)&lt;U6'410088' '410776'long_name :station or node identification code<pre>array(['410088', '410776'], dtype='&lt;U6')</pre></li></ul></li><li>Indexes: (1)<ul><li>station_idPandasIndex<pre>PandasIndex(Index(['410088', '410776'], dtype='object', name='station_id'))</pre></li></ul></li><li>Attributes: (3)long_name :longitudeunits :degrees_eastaxis :x</li></ul> <p>Placeholder section</p> <p>This key feature is under (re)construction. The statemements to do so will be as concise as possible while leaving future options open:</p> <pre>efts_ds = EftsDataset(d)\nefts_ds.to_stf(path=\"/home/user/data/streamflow_forecasts.nc\", version=\"2.0\")\n</pre> <p>The package includes functions to validate netCDF STF 2.0  files before loading</p> <p>These will also be available from command line interfaces.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"nb/basic_usage/#basic-use","title":"Basic use\u00b6","text":"<p><code>efts-io</code> is primarily about saving ensemble forecast time series to (resp. loading from) files on disk in netCDF STF 2.0 compliant format, from Python.</p> <p>While most similar implementations in e.g. R, Matlab so var have been closely related to netCDF file handling, in Python <code>xarray</code> is a de facto standard for the high level manipulation of tensor-like, multidimensional data. There is a partial mismatch between the STF netCDF conventions devised ten years ago and limited by the capabilities of Fortran netCDF libraries at the time, and the best practices for <code>xarray</code> in-memory representations. <code>efts-io</code> is a package bridging the technical gap between these two representations, and reducing the risk of data handling bugs by users when trying to reconcile this technical gap.</p>"},{"location":"nb/basic_usage/#creating-a-new-stf-xarray-dataset","title":"Creating a new STF xarray dataset\u00b6","text":"<p>There are several ways to create a dataset for EFTS with <code>efts-io</code>. One helper function to create a data set is <code>xr_efts</code>, particularly if you know upfront the geometry (dimensions) of your dataset:</p>"},{"location":"nb/basic_usage/#climate-and-forecast-conventions","title":"Climate and Forecast conventions\u00b6","text":"<p>Placeholder section.</p> <p>We may want to have the package cf-xarray as a dependency of <code>efts-io</code>, if it brings added value.</p>"},{"location":"nb/basic_usage/#saving-as-stf-20-compliant","title":"Saving as STF 2.0 compliant\u00b6","text":""},{"location":"nb/basic_usage/#validating-compliance","title":"Validating compliance\u00b6","text":""},{"location":"nb/design_rationale/","title":"Design rationale","text":"In\u00a0[1]: Copied! <pre>import xarray as xr\n</pre> import xarray as xr In\u00a0[2]: Copied! <pre>import netCDF4 as nc\n</pre> import netCDF4 as nc <p><code>xarray.open_dataset</code> has arguments to turn on/off the decoding of climate and forecast (SF) and related conventions.</p> <ul> <li><code>decode_times=False</code> is a must, otherwise the statement fails. Decoding would work for the <code>time</code> dimension, but decoding <code>lead_time</code> fails.</li> <li><code>decode_cf</code> seems to influence at least how the station_name variable appears, notably whether it ends up of dimensions <code>(station, strLen)</code> if True, or <code>(station,)</code> if False.</li> </ul> In\u00a0[3]: Copied! <pre>fn = \"/home/per202/data/sf/sample/HT_swiftRain_daily_stfv2_2000111523+0000-2023111023+0000.nc\"\nrain_xr = xr.open_dataset(fn, decode_times=False, decode_cf=False)\n</pre> fn = \"/home/per202/data/sf/sample/HT_swiftRain_daily_stfv2_2000111523+0000-2023111023+0000.nc\" rain_xr = xr.open_dataset(fn, decode_times=False, decode_cf=False) In\u00a0[4]: Copied! <pre>rain_nc = nc.Dataset(fn)\n</pre> rain_nc = nc.Dataset(fn) In\u00a0[5]: Copied! <pre>rain_xr\n</pre> rain_xr Out[5]: <pre>&lt;xarray.Dataset&gt; Size: 19MB\nDimensions:       (time: 8396, station: 563, lead_time: 1, strLen: 30,\n                   ens_member: 1)\nCoordinates:\n  * time          (time) int32 34kB 1 2 3 4 5 6 ... 8392 8393 8394 8395 8396\n  * station       (station) int32 2kB 1 2 3 4 5 6 7 ... 558 559 560 561 562 563\n  * lead_time     (lead_time) int32 4B 0\n  * ens_member    (ens_member) int32 4B 1\nDimensions without coordinates: strLen\nData variables:\n    station_id    (station) int32 2kB ...\n    station_name  (station, strLen) |S1 17kB ...\n    lat           (station) float32 2kB ...\n    lon           (station) float32 2kB ...\n    area          (station) float32 2kB ...\n    rain_obs      (time, ens_member, station, lead_time) float32 19MB ...\nAttributes:\n    title:                   Precip from Hydro Tasmania's observation network...\n    institution:             CSIRO Land &amp; Water\n    source:                  \n    catchment:               Hydro Tas\n    STF_convention_version:  2.0\n    STF_nc_spec:             https://wiki.csiro.au/display/wirada/NetCDF+for+...\n    comment:                 \n    history:                 2024-07-25 15:28:34 +10.0 - File created</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>time: 8396</li><li>station: 563</li><li>lead_time: 1</li><li>strLen: 30</li><li>ens_member: 1</li></ul></li><li>Coordinates: (4)<ul><li>time(time)int321 2 3 4 5 ... 8393 8394 8395 8396standard_name :timelong_name :timetime_standard :UTCaxis :tunits :days since 2000-11-14 23:00:00.0 +0000<pre>array([   1,    2,    3, ..., 8394, 8395, 8396], dtype=int32)</pre></li><li>station(station)int321 2 3 4 5 6 ... 559 560 561 562 563<pre>array([  1,   2,   3, ..., 561, 562, 563], dtype=int32)</pre></li><li>lead_time(lead_time)int320standard_name :lead timelong_name :forecast lead timeaxis :vunits :days since time<pre>array([0], dtype=int32)</pre></li><li>ens_member(ens_member)int321standard_name :ens_memberlong_name :ensemble memberunits :member idaxis :u<pre>array([1], dtype=int32)</pre></li></ul></li><li>Data variables: (6)<ul><li>station_id(station)int32...long_name :station or node identification code<pre>[563 values with dtype=int32]</pre></li><li>station_name(station, strLen)|S1...long_name :station or node name<pre>[16890 values with dtype=|S1]</pre></li><li>lat(station)float32...long_name :latitudeunits :degrees_northaxis :y<pre>[563 values with dtype=float32]</pre></li><li>lon(station)float32...long_name :longitudeunits :degrees_eastaxis :x<pre>[563 values with dtype=float32]</pre></li><li>area(station)float32...units :sqkm_FillValue :-1.0standard_name :arealong_name :station area<pre>[563 values with dtype=float32]</pre></li><li>rain_obs(time, ens_member, station, lead_time)float32...standard_name :rain_obslong_name :observed rainfallunits :mm_FillValue :-9999.0type :2.0type_description :accumulated over the preceding intervaldat_type :derdat_type_description :derived (from observations)location_type :area<pre>[4726948 values with dtype=float32]</pre></li></ul></li><li>Indexes: (4)<ul><li>timePandasIndex<pre>PandasIndex(Index([   1,    2,    3,    4,    5,    6,    7,    8,    9,   10,\n       ...\n       8387, 8388, 8389, 8390, 8391, 8392, 8393, 8394, 8395, 8396],\n      dtype='int32', name='time', length=8396))</pre></li><li>stationPandasIndex<pre>PandasIndex(Index([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n       ...\n       554, 555, 556, 557, 558, 559, 560, 561, 562, 563],\n      dtype='int32', name='station', length=563))</pre></li><li>lead_timePandasIndex<pre>PandasIndex(Index([0], dtype='int32', name='lead_time'))</pre></li><li>ens_memberPandasIndex<pre>PandasIndex(Index([1], dtype='int32', name='ens_member'))</pre></li></ul></li><li>Attributes: (8)title :Precip from Hydro Tasmania's observation network areally averaged with inverse distance squared weightinginstitution :CSIRO Land &amp; Watersource :catchment :Hydro TasSTF_convention_version :2.0STF_nc_spec :https://wiki.csiro.au/display/wirada/NetCDF+for+SWIFTcomment :history :2024-07-25 15:28:34 +10.0 - File created</li></ul> <p>If we use <code>decode_cf=True</code>, we seem to get a one dimensional array of array of bytes, rather than a matrix of bytes (type 'S1'):</p> In\u00a0[6]: Copied! <pre>rain_cfdecode = xr.open_dataset(fn, decode_times=False, decode_cf=True)\n</pre> rain_cfdecode = xr.open_dataset(fn, decode_times=False, decode_cf=True) In\u00a0[7]: Copied! <pre>rain_cfdecode.station_name\n</pre> rain_cfdecode.station_name Out[7]: <pre>&lt;xarray.DataArray 'station_name' (station: 563)&gt; Size: 17kB\n[563 values with dtype=|S30]\nCoordinates:\n  * station  (station) int32 2kB 1 2 3 4 5 6 7 8 ... 557 558 559 560 561 562 563\nAttributes:\n    long_name:  station or node name</pre>xarray.DataArray'station_name'<ul><li>station: 563</li></ul><ul><li>...<pre>[563 values with dtype=|S30]</pre></li><li>Coordinates: (1)<ul><li>station(station)int321 2 3 4 5 6 ... 559 560 561 562 563<pre>array([  1,   2,   3, ..., 561, 562, 563], dtype=int32)</pre></li></ul></li><li>Indexes: (1)<ul><li>stationPandasIndex<pre>PandasIndex(Index([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n       ...\n       554, 555, 556, 557, 558, 559, 560, 561, 562, 563],\n      dtype='int32', name='station', length=563))</pre></li></ul></li><li>Attributes: (1)long_name :station or node name</li></ul> In\u00a0[8]: Copied! <pre>rain_cfdecode.station_name.values[1]\n</pre> rain_cfdecode.station_name.values[1] Out[8]: <pre>np.bytes_(b'19629011')</pre> In\u00a0[9]: Copied! <pre>rain_nc\n</pre> rain_nc Out[9]: <pre>&lt;class 'netCDF4._netCDF4.Dataset'&gt;\nroot group (NETCDF3_CLASSIC data model, file format NETCDF3):\n    title: Precip from Hydro Tasmania's observation network areally averaged with inverse distance squared weighting\n    institution: CSIRO Land &amp; Water\n    source: \n    catchment: Hydro Tas\n    STF_convention_version: 2.0\n    STF_nc_spec: https://wiki.csiro.au/display/wirada/NetCDF+for+SWIFT\n    comment: \n    history: 2024-07-25 15:28:34 +10.0 - File created\n    dimensions(sizes): time(8396), station(563), lead_time(1), strLen(30), ens_member(1)\n    variables(dimensions): int32 time(time), int32 station(station), int32 lead_time(lead_time), int32 station_id(station), |S1 station_name(station, strLen), int32 ens_member(ens_member), float32 lat(station), float32 lon(station), float32 area(station), float32 rain_obs(time, ens_member, station, lead_time)\n    groups: </pre> <p>Modulo the value of <code>decode_cf</code> for <code>xarray.open_dataset</code>, the shape of the data in memory appears consistent between <code>xarray</code> and <code>netCDF4</code></p> In\u00a0[10]: Copied! <pre>rain_cfdecode\n</pre> rain_cfdecode Out[10]: <pre>&lt;xarray.Dataset&gt; Size: 19MB\nDimensions:       (time: 8396, station: 563, lead_time: 1, ens_member: 1)\nCoordinates:\n  * time          (time) int32 34kB 1 2 3 4 5 6 ... 8392 8393 8394 8395 8396\n  * station       (station) int32 2kB 1 2 3 4 5 6 7 ... 558 559 560 561 562 563\n  * lead_time     (lead_time) int32 4B 0\n  * ens_member    (ens_member) int32 4B 1\nData variables:\n    station_id    (station) int32 2kB ...\n    station_name  (station) |S30 17kB b'18594010' b'19629011' ... b'28294677'\n    lat           (station) float32 2kB ...\n    lon           (station) float32 2kB ...\n    area          (station) float32 2kB ...\n    rain_obs      (time, ens_member, station, lead_time) float32 19MB ...\nAttributes:\n    title:                   Precip from Hydro Tasmania's observation network...\n    institution:             CSIRO Land &amp; Water\n    source:                  \n    catchment:               Hydro Tas\n    STF_convention_version:  2.0\n    STF_nc_spec:             https://wiki.csiro.au/display/wirada/NetCDF+for+...\n    comment:                 \n    history:                 2024-07-25 15:28:34 +10.0 - File created</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>time: 8396</li><li>station: 563</li><li>lead_time: 1</li><li>ens_member: 1</li></ul></li><li>Coordinates: (4)<ul><li>time(time)int321 2 3 4 5 ... 8393 8394 8395 8396standard_name :timelong_name :timetime_standard :UTCaxis :tunits :days since 2000-11-14 23:00:00.0 +0000<pre>array([   1,    2,    3, ..., 8394, 8395, 8396], dtype=int32)</pre></li><li>station(station)int321 2 3 4 5 6 ... 559 560 561 562 563<pre>array([  1,   2,   3, ..., 561, 562, 563], dtype=int32)</pre></li><li>lead_time(lead_time)int320standard_name :lead timelong_name :forecast lead timeaxis :vunits :days since time<pre>array([0], dtype=int32)</pre></li><li>ens_member(ens_member)int321standard_name :ens_memberlong_name :ensemble memberunits :member idaxis :u<pre>array([1], dtype=int32)</pre></li></ul></li><li>Data variables: (6)<ul><li>station_id(station)int32...long_name :station or node identification code<pre>[563 values with dtype=int32]</pre></li><li>station_name(station)|S30b'18594010' ... b'28294677'long_name :station or node name<pre>array([b'18594010', b'19629011', b'18562015', ..., b'28286670', b'28294676',\n       b'28294677'], dtype='|S30')</pre></li><li>lat(station)float32...long_name :latitudeunits :degrees_northaxis :y<pre>[563 values with dtype=float32]</pre></li><li>lon(station)float32...long_name :longitudeunits :degrees_eastaxis :x<pre>[563 values with dtype=float32]</pre></li><li>area(station)float32...units :sqkmstandard_name :arealong_name :station area<pre>[563 values with dtype=float32]</pre></li><li>rain_obs(time, ens_member, station, lead_time)float32...standard_name :rain_obslong_name :observed rainfallunits :mmtype :2.0type_description :accumulated over the preceding intervaldat_type :derdat_type_description :derived (from observations)location_type :area<pre>[4726948 values with dtype=float32]</pre></li></ul></li><li>Indexes: (4)<ul><li>timePandasIndex<pre>PandasIndex(Index([   1,    2,    3,    4,    5,    6,    7,    8,    9,   10,\n       ...\n       8387, 8388, 8389, 8390, 8391, 8392, 8393, 8394, 8395, 8396],\n      dtype='int32', name='time', length=8396))</pre></li><li>stationPandasIndex<pre>PandasIndex(Index([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n       ...\n       554, 555, 556, 557, 558, 559, 560, 561, 562, 563],\n      dtype='int32', name='station', length=563))</pre></li><li>lead_timePandasIndex<pre>PandasIndex(Index([0], dtype='int32', name='lead_time'))</pre></li><li>ens_memberPandasIndex<pre>PandasIndex(Index([1], dtype='int32', name='ens_member'))</pre></li></ul></li><li>Attributes: (8)title :Precip from Hydro Tasmania's observation network areally averaged with inverse distance squared weightinginstitution :CSIRO Land &amp; Watersource :catchment :Hydro TasSTF_convention_version :2.0STF_nc_spec :https://wiki.csiro.au/display/wirada/NetCDF+for+SWIFTcomment :history :2024-07-25 15:28:34 +10.0 - File created</li></ul> In\u00a0[11]: Copied! <pre>from xarray.coding import times\n</pre> from xarray.coding import times In\u00a0[12]: Copied! <pre>decod = times.CFDatetimeCoder(use_cftime=True)\n</pre> decod = times.CFDatetimeCoder(use_cftime=True) In\u00a0[13]: Copied! <pre>decod.decode?\n</pre> decod.decode? <pre>Signature: decod.decode(variable: 'Variable', name: 'T_Name' = None) -&gt; 'Variable'\nDocstring: Convert an decoded variable to a encoded variable\nFile:      ~/src/efts-io/.venv/lib/python3.12/site-packages/xarray/coding/times.py\nType:      method</pre> <p>We need to pass a \"Variable\", not a <code>DataArray</code></p> In\u00a0[14]: Copied! <pre>type(rain_cfdecode.coords['time'])\n</pre> type(rain_cfdecode.coords['time']) Out[14]: <pre>xarray.core.dataarray.DataArray</pre> In\u00a0[15]: Copied! <pre>TIME_DIMNAME=\"time\"\nvar = xr.as_variable(rain_cfdecode.coords[TIME_DIMNAME])\n</pre> TIME_DIMNAME=\"time\" var = xr.as_variable(rain_cfdecode.coords[TIME_DIMNAME]) In\u00a0[16]: Copied! <pre>time_zone = var.attrs[\"time_standard\"]\ntime_coords = decod.decode(var, name=TIME_DIMNAME)\n</pre> time_zone = var.attrs[\"time_standard\"] time_coords = decod.decode(var, name=TIME_DIMNAME) In\u00a0[17]: Copied! <pre>time_zone\n</pre> time_zone Out[17]: <pre>'UTC'</pre> In\u00a0[18]: Copied! <pre>timestamp = time_coords.values[0]\ntimestamp\n</pre> timestamp = time_coords.values[0] timestamp Out[18]: <pre>cftime.DatetimeGregorian(2000, 11, 15, 23, 0, 0, 0, has_year_zero=False)</pre> <p>Date/time, calendar and time zone handling are a topic of underappreciated complexity, to put it mildly. Let's look at what we get here.</p> <p>Unfamiliar with this type of time stamp. It seems not to have time zone from the decoding operation, but can have it:</p> In\u00a0[19]: Copied! <pre>timestamp.tzinfo is None\n</pre> timestamp.tzinfo is None Out[19]: <pre>True</pre> <p>Should our new <code>time</code> axis hold time zone info with each time stamp, or still rely on the coordinate attribute <code>time_standard</code>?</p> In\u00a0[20]: Copied! <pre>from efts_io.wrapper import cftimes_to_pdtstamps\n</pre> from efts_io.wrapper import cftimes_to_pdtstamps In\u00a0[21]: Copied! <pre>new_time_values = cftimes_to_pdtstamps(\n    time_coords.values,\n    time_zone,\n)\nnew_time_values\n</pre> new_time_values = cftimes_to_pdtstamps(     time_coords.values,     time_zone, ) new_time_values Out[21]: <pre>array([Timestamp('2000-11-15 23:00:00+0000', tz='UTC'),\n       Timestamp('2000-11-16 23:00:00+0000', tz='UTC'),\n       Timestamp('2000-11-17 23:00:00+0000', tz='UTC'), ...,\n       Timestamp('2023-11-08 23:00:00+0000', tz='UTC'),\n       Timestamp('2023-11-09 23:00:00+0000', tz='UTC'),\n       Timestamp('2023-11-10 23:00:00+0000', tz='UTC')], dtype=object)</pre> <p>This may be a suitable time axis. Depending on usage needs we may want to revisit though. In particular, users may create \"naive\" date time stamps from strings: how would <code>ds.sel()</code> then behave if time stamps have time zones??</p> In\u00a0[22]: Copied! <pre>import pandas as pd\npd.Timestamp('2000-11-15 23:00:00+0000')\n</pre> import pandas as pd pd.Timestamp('2000-11-15 23:00:00+0000') Out[22]: <pre>Timestamp('2000-11-15 23:00:00+0000', tz='UTC')</pre> In\u00a0[23]: Copied! <pre>pd.Timestamp('2000-11-15 23:00:00+0000') == new_time_values[0]\n</pre> pd.Timestamp('2000-11-15 23:00:00+0000') == new_time_values[0] Out[23]: <pre>True</pre> In\u00a0[24]: Copied! <pre>pd.Timestamp('2000-11-15 23:00:00')\n</pre> pd.Timestamp('2000-11-15 23:00:00') Out[24]: <pre>Timestamp('2000-11-15 23:00:00')</pre> In\u00a0[25]: Copied! <pre>pd.Timestamp('2000-11-15 23:00:00') == new_time_values[0]\n</pre> pd.Timestamp('2000-11-15 23:00:00') == new_time_values[0] Out[25]: <pre>False</pre> <p>As expected, the naive date time is not equal to the one with a time zone. Using time zone in the time stamps may be a fraught choice in practice. In particular there may be logical but unintuitive if we use a time <code>slice</code> to subset data</p> <p>See also github issue 3</p> In\u00a0[26]: Copied! <pre>new_time_values = cftimes_to_pdtstamps(\n    time_coords.values,\n    None,\n)\nnew_time_values\n</pre> new_time_values = cftimes_to_pdtstamps(     time_coords.values,     None, ) new_time_values Out[26]: <pre>array([Timestamp('2000-11-15 23:00:00'), Timestamp('2000-11-16 23:00:00'),\n       Timestamp('2000-11-17 23:00:00'), ...,\n       Timestamp('2023-11-08 23:00:00'), Timestamp('2023-11-09 23:00:00'),\n       Timestamp('2023-11-10 23:00:00')], dtype=object)</pre> In\u00a0[27]: Copied! <pre>station_ids = rain_cfdecode.station_id.values\nstation_ids.dtype\n</pre> station_ids = rain_cfdecode.station_id.values station_ids.dtype Out[27]: <pre>dtype('int32')</pre> In\u00a0[28]: Copied! <pre>station_ids[:3]\n</pre> station_ids[:3] Out[28]: <pre>array([18594010, 19629011, 18562015], dtype=int32)</pre> <p>STF conventions are such that the station ID can only be an integer. We want a <code>str</code> in the in memory model. This is easy going one direction; when we consider going the other way (writing to STF 2.0) this will be trickier.</p> In\u00a0[29]: Copied! <pre>station_ids_str = [str(x) for x in station_ids]\n</pre> station_ids_str = [str(x) for x in station_ids] In\u00a0[30]: Copied! <pre>rain_cfdecode.station_id\n</pre> rain_cfdecode.station_id Out[30]: <pre>&lt;xarray.DataArray 'station_id' (station: 563)&gt; Size: 2kB\narray([18594010, 19629011, 18562015, ..., 28286670, 28294676, 28294677],\n      dtype=int32)\nCoordinates:\n  * station  (station) int32 2kB 1 2 3 4 5 6 7 8 ... 557 558 559 560 561 562 563\nAttributes:\n    long_name:  station or node identification code</pre>xarray.DataArray'station_id'<ul><li>station: 563</li></ul><ul><li>18594010 19629011 18562015 18562003 ... 28286670 28294676 28294677<pre>array([18594010, 19629011, 18562015, ..., 28286670, 28294676, 28294677],\n      dtype=int32)</pre></li><li>Coordinates: (1)<ul><li>station(station)int321 2 3 4 5 6 ... 559 560 561 562 563<pre>array([  1,   2,   3, ..., 561, 562, 563], dtype=int32)</pre></li></ul></li><li>Indexes: (1)<ul><li>stationPandasIndex<pre>PandasIndex(Index([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n       ...\n       554, 555, 556, 557, 558, 559, 560, 561, 562, 563],\n      dtype='int32', name='station', length=563))</pre></li></ul></li><li>Attributes: (1)long_name :station or node identification code</li></ul> In\u00a0[31]: Copied! <pre>type(rain_cfdecode.station_id)\n</pre> type(rain_cfdecode.station_id) Out[31]: <pre>xarray.core.dataarray.DataArray</pre> In\u00a0[32]: Copied! <pre>rain_cfdecode.station\n</pre> rain_cfdecode.station Out[32]: <pre>&lt;xarray.DataArray 'station' (station: 563)&gt; Size: 2kB\narray([  1,   2,   3, ..., 561, 562, 563], dtype=int32)\nCoordinates:\n  * station  (station) int32 2kB 1 2 3 4 5 6 7 8 ... 557 558 559 560 561 562 563</pre>xarray.DataArray'station'<ul><li>station: 563</li></ul><ul><li>1 2 3 4 5 6 7 8 9 10 11 ... 554 555 556 557 558 559 560 561 562 563<pre>array([  1,   2,   3, ..., 561, 562, 563], dtype=int32)</pre></li><li>Coordinates: (1)<ul><li>station(station)int321 2 3 4 5 6 ... 559 560 561 562 563<pre>array([  1,   2,   3, ..., 561, 562, 563], dtype=int32)</pre></li></ul></li><li>Indexes: (1)<ul><li>stationPandasIndex<pre>PandasIndex(Index([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n       ...\n       554, 555, 556, 557, 558, 559, 560, 561, 562, 563],\n      dtype='int32', name='station', length=563))</pre></li></ul></li><li>Attributes: (0)</li></ul> In\u00a0[33]: Copied! <pre>type(rain_cfdecode.station)\n</pre> type(rain_cfdecode.station) Out[33]: <pre>xarray.core.dataarray.DataArray</pre> <p>A key thing here is that we will promote \"station_id\" which is a variable, to a coordinate, so we cannot just assign dimensions; we will need to reconstruct a new xarray.</p> In\u00a0[34]: Copied! <pre>rain_cfdecode.station_name\n</pre> rain_cfdecode.station_name Out[34]: <pre>&lt;xarray.DataArray 'station_name' (station: 563)&gt; Size: 17kB\narray([b'18594010', b'19629011', b'18562015', ..., b'28286670', b'28294676',\n       b'28294677'], dtype='|S30')\nCoordinates:\n  * station  (station) int32 2kB 1 2 3 4 5 6 7 8 ... 557 558 559 560 561 562 563\nAttributes:\n    long_name:  station or node name</pre>xarray.DataArray'station_name'<ul><li>station: 563</li></ul><ul><li>b'18594010' b'19629011' b'18562015' ... b'28294676' b'28294677'<pre>array([b'18594010', b'19629011', b'18562015', ..., b'28286670', b'28294676',\n       b'28294677'], dtype='|S30')</pre></li><li>Coordinates: (1)<ul><li>station(station)int321 2 3 4 5 6 ... 559 560 561 562 563<pre>array([  1,   2,   3, ..., 561, 562, 563], dtype=int32)</pre></li></ul></li><li>Indexes: (1)<ul><li>stationPandasIndex<pre>PandasIndex(Index([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n       ...\n       554, 555, 556, 557, 558, 559, 560, 561, 562, 563],\n      dtype='int32', name='station', length=563))</pre></li></ul></li><li>Attributes: (1)long_name :station or node name</li></ul> In\u00a0[35]: Copied! <pre>x = b'18594010'\nstr(x, encoding=\"UTF-8\")\n</pre> x = b'18594010' str(x, encoding=\"UTF-8\") Out[35]: <pre>'18594010'</pre> <p>Using helper functions already included in the package at the time of writing:</p> In\u00a0[36]: Copied! <pre>from efts_io.wrapper import byte_stations_to_str\n</pre> from efts_io.wrapper import byte_stations_to_str In\u00a0[37]: Copied! <pre>station_name_str = byte_stations_to_str(rain_cfdecode.station_name.values)\nstation_name_str[:3]\n</pre> station_name_str = byte_stations_to_str(rain_cfdecode.station_name.values) station_name_str[:3] Out[37]: <pre>array(['18594010', '19629011', '18562015'], dtype='&lt;U8')</pre> In\u00a0[38]: Copied! <pre>from efts_io import wrapper as w\n</pre> from efts_io import wrapper as w In\u00a0[39]: Copied! <pre>rain_cfdecode.ens_member.values\n</pre> rain_cfdecode.ens_member.values Out[39]: <pre>array([1], dtype=int32)</pre> In\u00a0[40]: Copied! <pre>issue_times = new_time_values\nstation_ids = station_ids_str\nlead_times = rain_cfdecode.lead_time.values\nlead_time_tstep = \"days\"\nensemble_size = len(rain_cfdecode.ens_member.values)\nstation_names= station_name_str\nnc_attributes = None\nlatitudes = rain_cfdecode.lat.values\nlongitudes = rain_cfdecode.lon.values\nareas = rain_cfdecode.area.values\n\nd = w.xr_efts(\n    issue_times,\n    station_ids,\n    lead_times,\n    lead_time_tstep,\n    ensemble_size,\n    station_names,\n    latitudes,\n    longitudes,\n    areas,\n    nc_attributes,\n)\n</pre> issue_times = new_time_values station_ids = station_ids_str lead_times = rain_cfdecode.lead_time.values lead_time_tstep = \"days\" ensemble_size = len(rain_cfdecode.ens_member.values) station_names= station_name_str nc_attributes = None latitudes = rain_cfdecode.lat.values longitudes = rain_cfdecode.lon.values areas = rain_cfdecode.area.values  d = w.xr_efts(     issue_times,     station_ids,     lead_times,     lead_time_tstep,     ensemble_size,     station_names,     latitudes,     longitudes,     areas,     nc_attributes, )  In\u00a0[41]: Copied! <pre>d.sizes\n</pre> d.sizes Out[41]: <pre>Frozen({'station': 563, 'time': 8396, 'ens_member': 1, 'lead_time': 1})</pre> In\u00a0[42]: Copied! <pre>d.sel(station_id=\"18594010\", drop=True)\n</pre> d.sel(station_id=\"18594010\", drop=True) Out[42]: <pre>&lt;xarray.Dataset&gt; Size: 67kB\nDimensions:       (time: 8396, ens_member: 1, lead_time: 1)\nCoordinates:\n  * time          (time) datetime64[ns] 67kB 2000-11-15T23:00:00 ... 2023-11-...\n  * ens_member    (ens_member) int64 8B 1\n  * lead_time     (lead_time) int32 4B 0\nData variables:\n    station_name  &lt;U8 32B '18594010'\n    lat           float32 4B -41.63\n    lon           float32 4B 146.3\n    area          float32 4B 8.743\nAttributes:\n    title:                   not provided\n    institution:             not provided\n    catchment:               not provided\n    source:                  not provided\n    comment:                 not provided\n    history:                 not provided\n    STF_convention_version:  2.0\n    STF_nc_spec:             https://github.com/csiro-hydroinformatics/efts/b...</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>time: 8396</li><li>ens_member: 1</li><li>lead_time: 1</li></ul></li><li>Coordinates: (3)<ul><li>time(time)datetime64[ns]2000-11-15T23:00:00 ... 2023-11-...standard_name :timelong_name :timeaxis :t<pre>array(['2000-11-15T23:00:00.000000000', '2000-11-16T23:00:00.000000000',\n       '2000-11-17T23:00:00.000000000', ..., '2023-11-08T23:00:00.000000000',\n       '2023-11-09T23:00:00.000000000', '2023-11-10T23:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li><li>ens_member(ens_member)int641standard_name :ens_memberlong_name :ensemble memberunits :member idaxis :u<pre>array([1])</pre></li><li>lead_time(lead_time)int320standard_name :lead timelong_name :forecast lead timeaxis :vunits :days since time<pre>array([0], dtype=int32)</pre></li></ul></li><li>Data variables: (4)<ul><li>station_name()&lt;U8'18594010'long_name :station or node name<pre>array('18594010', dtype='&lt;U8')</pre></li><li>lat()float32-41.63long_name :latitudeunits :degrees_northaxis :y<pre>array(-41.631687, dtype=float32)</pre></li><li>lon()float32146.3long_name :longitudeunits :degrees_eastaxis :x<pre>array(146.25577, dtype=float32)</pre></li><li>area()float328.743long_name :station areaunits :km^2standard_name :area<pre>array(8.742642, dtype=float32)</pre></li></ul></li><li>Indexes: (3)<ul><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2000-11-15 23:00:00', '2000-11-16 23:00:00',\n               '2000-11-17 23:00:00', '2000-11-18 23:00:00',\n               '2000-11-19 23:00:00', '2000-11-20 23:00:00',\n               '2000-11-21 23:00:00', '2000-11-22 23:00:00',\n               '2000-11-23 23:00:00', '2000-11-24 23:00:00',\n               ...\n               '2023-11-01 23:00:00', '2023-11-02 23:00:00',\n               '2023-11-03 23:00:00', '2023-11-04 23:00:00',\n               '2023-11-05 23:00:00', '2023-11-06 23:00:00',\n               '2023-11-07 23:00:00', '2023-11-08 23:00:00',\n               '2023-11-09 23:00:00', '2023-11-10 23:00:00'],\n              dtype='datetime64[ns]', name='time', length=8396, freq=None))</pre></li><li>ens_memberPandasIndex<pre>PandasIndex(Index([1], dtype='int64', name='ens_member'))</pre></li><li>lead_timePandasIndex<pre>PandasIndex(Index([0], dtype='int32', name='lead_time'))</pre></li></ul></li><li>Attributes: (8)title :not providedinstitution :not providedcatchment :not providedsource :not providedcomment :not providedhistory :not providedSTF_convention_version :2.0STF_nc_spec :https://github.com/csiro-hydroinformatics/efts/blob/d7d43a995fb5e459bcb894e09b7bb89de03e285c/docs/netcdf_for_water_forecasting.md</li></ul> In\u00a0[43]: Copied! <pre>set(d.variables.keys())\n</pre> set(d.variables.keys()) Out[43]: <pre>{'area',\n 'ens_member',\n 'lat',\n 'lead_time',\n 'lon',\n 'station',\n 'station_id',\n 'station_name',\n 'time'}</pre> In\u00a0[44]: Copied! <pre>set(rain_cfdecode.variables.keys())\n</pre> set(rain_cfdecode.variables.keys()) Out[44]: <pre>{'area',\n 'ens_member',\n 'lat',\n 'lead_time',\n 'lon',\n 'rain_obs',\n 'station',\n 'station_id',\n 'station_name',\n 'time'}</pre> In\u00a0[45]: Copied! <pre>rain_cfdecode.rain_obs.dims\n</pre> rain_cfdecode.rain_obs.dims Out[45]: <pre>('time', 'ens_member', 'station', 'lead_time')</pre> In\u00a0[46]: Copied! <pre>da = rain_cfdecode.rain_obs\n</pre> da = rain_cfdecode.rain_obs <p>Assigning the data variable straight is not possible due to the differing names for the coordinate(s) for the station ids: we'd end up with 5 dimensions:</p> In\u00a0[47]: Copied! <pre>d\n</pre> d Out[47]: <pre>&lt;xarray.Dataset&gt; Size: 114kB\nDimensions:       (station: 563, time: 8396, ens_member: 1, lead_time: 1)\nCoordinates:\n  * time          (time) datetime64[ns] 67kB 2000-11-15T23:00:00 ... 2023-11-...\n  * station       (station) int64 5kB 1 2 3 4 5 6 7 ... 558 559 560 561 562 563\n  * ens_member    (ens_member) int64 8B 1\n  * lead_time     (lead_time) int32 4B 0\n  * station_id    (station) &lt;U8 18kB '18594010' '19629011' ... '28294677'\nData variables:\n    station_name  (station) &lt;U8 18kB '18594010' '19629011' ... '28294677'\n    lat           (station) float32 2kB -41.63 -41.72 -41.78 ... -41.82 -41.85\n    lon           (station) float32 2kB 146.3 146.4 146.2 ... 145.6 145.6 145.6\n    area          (station) float32 2kB 8.743 8.05 24.13 ... 3.353 1.76 4.988\nAttributes:\n    title:                   not provided\n    institution:             not provided\n    catchment:               not provided\n    source:                  not provided\n    comment:                 not provided\n    history:                 not provided\n    STF_convention_version:  2.0\n    STF_nc_spec:             https://github.com/csiro-hydroinformatics/efts/b...</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>station: 563</li><li>time: 8396</li><li>ens_member: 1</li><li>lead_time: 1</li></ul></li><li>Coordinates: (5)<ul><li>time(time)datetime64[ns]2000-11-15T23:00:00 ... 2023-11-...standard_name :timelong_name :timeaxis :t<pre>array(['2000-11-15T23:00:00.000000000', '2000-11-16T23:00:00.000000000',\n       '2000-11-17T23:00:00.000000000', ..., '2023-11-08T23:00:00.000000000',\n       '2023-11-09T23:00:00.000000000', '2023-11-10T23:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li><li>station(station)int641 2 3 4 5 6 ... 559 560 561 562 563<pre>array([  1,   2,   3, ..., 561, 562, 563])</pre></li><li>ens_member(ens_member)int641standard_name :ens_memberlong_name :ensemble memberunits :member idaxis :u<pre>array([1])</pre></li><li>lead_time(lead_time)int320standard_name :lead timelong_name :forecast lead timeaxis :vunits :days since time<pre>array([0], dtype=int32)</pre></li><li>station_id(station)&lt;U8'18594010' ... '28294677'long_name :station or node identification code<pre>array(['18594010', '19629011', '18562015', ..., '28286670', '28294676',\n       '28294677'], dtype='&lt;U8')</pre></li></ul></li><li>Data variables: (4)<ul><li>station_name(station)&lt;U8'18594010' ... '28294677'long_name :station or node name<pre>array(['18594010', '19629011', '18562015', '18562003', '18562002',\n       '18562020', '18562005', '18562007', '18562008', '18562012',\n       '18562009', '18562010', '18562021', '18562013', '18562017',\n       '18562014', '18562018', '18594027', '18594028', '18594029',\n       '18594030', '18594031', '18594033', '18594034', '19631035',\n       '18594036', '18594038', '18594040', '19629041', '19629042',\n       '19629043', '19629044', '19629053', '19629046', '19629048',\n       '19162011', '19629052', '18562019', '18562006', '18562001',\n       '18562016', '27657058', '27657059', '27657060', '27657061',\n       '27657062', '27657066', '27657067', '27657071', '27657072',\n       '27656075', '27656077', '27656078', '27656079', '27656080',\n       '27656081', '27656082', '26415015', '27742098', '27742099',\n       '27742109', '27742101', '27742102', '27742103', '27742104',\n       '27742105', '27742106', '27742108', '28286117', '28294118',\n       '29370120', '11625124', '23759025', '22122130', '21211002',\n       '10179003', '10170002', '10128137', '10190954', '10573143',\n       '28286002', '29370001', '28294004', '10128001', '18594001',\n       '11627001', '27657001', '11625001', '11613001', '11604001',\n       '10170001', '10553001', '10580001', '10579001', '10573001',\n       '10190001', '10592001', '27658001', '19629001', '19631001',\n...\n       '10179004', '10179005', '10179006', '10179007', '10179008',\n       '10179010', '12001641', '24553002', '24553008', '24553004',\n       '24553005', '24553006', '24553007', '10565009', '16799037',\n       '18562004', '18562011', '19629045', '19661548', '19631549',\n       '19006321', '10001231', '10190955', '26415018', '10565006',\n       '10565053', '10565054', '10565055', '10565056', '10565057',\n       '10565059', '10565058', '10565014', '32139002', '10167002',\n       '10167003', '10176002', '10168002', '10169002', '10580142',\n       '28294001', '32139001', '10169001', '10179001', '10168001',\n       '10176001', '10167001', '11613604', '28294678', '15189002',\n       '10128893', '10573992', '10573999', '10565003', '10565012',\n       '10565023', '10565027', '10565034', '13155108', '13155109',\n       '31418007', '31418010', '31418004', '10179009', '12158735',\n       '30236015', '10565060', '10004151', '26415019', '26001801',\n       '12158747', '16249123', '16249122', '10190945', '10190946',\n       '10579916', '10007591', '10001711', '23171017', '23171015',\n       '22122918', '22002111', '23004971', '23171012', '10579921',\n       '12158740', '12004891', '12003011', '32005971', '32139003',\n       '32139004', '10005071', '10000541', '10008261', '10565028',\n       '28286670', '28294676', '28294677'], dtype='&lt;U8')</pre></li><li>lat(station)float32-41.63 -41.72 ... -41.82 -41.85long_name :latitudeunits :degrees_northaxis :y<pre>array([-41.631687, -41.7165  , -41.776894, -41.93974 , -41.89406 ,\n       -41.91518 , -41.913536, -41.860268, -41.802822, -41.85331 ,\n       -41.881172, -41.86824 , -41.83606 , -41.843746, -41.799908,\n       -41.80077 , -41.77146 , -41.781002, -41.750923, -41.72675 ,\n       -41.712585, -41.697426, -41.74191 , -41.712852, -41.69828 ,\n       -41.70118 , -41.674202, -41.648064, -41.749176, -41.74841 ,\n       -41.72291 , -41.719963, -41.727497, -41.726566, -41.68101 ,\n       -41.696434, -41.715874, -41.752   , -41.89081 , -41.775448,\n       -41.80732 , -41.902855, -42.01951 , -41.968296, -41.9471  ,\n       -41.851048, -41.770805, -41.8138  , -41.91512 , -41.848503,\n       -41.77807 , -41.692287, -41.690037, -41.573517, -41.594967,\n       -41.583652, -41.64903 , -41.92355 , -41.60278 , -41.528053,\n       -41.537727, -41.545124, -41.547276, -41.587067, -41.625458,\n       -41.675533, -41.668636, -41.711624, -41.866405, -41.932465,\n       -42.002964, -41.564877, -42.082386, -42.086395, -42.174744,\n       -42.22117 , -42.275208, -42.11975 , -42.397804, -42.605015,\n       -41.87931 , -41.991184, -41.914623, -42.22994 , -41.650127,\n       -41.30872 , -41.833553, -41.525406, -41.47772 , -41.38934 ,\n       -42.2766  , -42.30613 , -42.49147 , -42.311035, -42.510754,\n       -42.394913, -42.437775, -41.736443, -41.675716, -41.65877 ,\n...\n       -42.25616 , -42.27091 , -42.239876, -42.209545, -42.187366,\n       -42.165   , -41.5289  , -42.252934, -42.28992 , -42.256786,\n       -42.24237 , -42.22594 , -42.198124, -42.476032, -42.119785,\n       -41.916996, -41.83074 , -41.737198, -41.633583, -41.656677,\n       -41.657032, -42.39504 , -42.385357, -42.042328, -42.295185,\n       -42.304424, -42.31551 , -42.36995 , -42.342033, -42.422092,\n       -42.388145, -42.260147, -42.35363 , -41.81894 , -42.20476 ,\n       -42.177784, -42.119568, -42.233315, -42.279427, -42.46545 ,\n       -41.887608, -41.883717, -42.266857, -42.26225 , -42.23631 ,\n       -42.15651 , -42.194283, -41.50659 , -41.878647, -41.726135,\n       -42.19374 , -42.525448, -42.50113 , -42.033215, -42.172466,\n       -42.53875 , -42.44366 , -42.149757, -41.83098 , -41.86145 ,\n       -42.021538, -41.967735, -41.86054 , -42.137127, -41.470856,\n       -41.97039 , -42.085102, -42.028996, -42.06697 , -42.016922,\n       -41.554066, -42.768085, -42.732998, -42.347584, -42.366074,\n       -42.1319  , -42.148197, -42.110012, -42.07383 , -42.018982,\n       -42.165733, -42.181515, -42.036633, -42.033264, -42.24517 ,\n       -41.688072, -41.701202, -41.7367  , -41.79801 , -41.885498,\n       -41.790764, -42.27026 , -42.391933, -42.481453, -42.48671 ,\n       -41.84537 , -41.818226, -41.85182 ], dtype=float32)</pre></li><li>lon(station)float32146.3 146.4 146.2 ... 145.6 145.6long_name :longitudeunits :degrees_eastaxis :x<pre>array([146.25577, 146.4181 , 146.19212, 146.15002, 146.2372 , 146.199  ,\n       146.1202 , 146.09334, 146.09958, 146.26053, 146.15012, 146.1904 ,\n       146.14641, 146.23631, 146.31026, 146.25847, 146.26228, 146.13474,\n       146.14459, 146.15536, 146.21718, 146.17564, 146.30244, 146.2579 ,\n       146.35551, 146.30156, 146.34909, 146.28381, 146.3831 , 146.4212 ,\n       146.34563, 146.35983, 146.38065, 146.45474, 146.41135, 146.38455,\n       146.39626, 146.23596, 146.06766, 146.21133, 146.22327, 145.99011,\n       145.96811, 145.97226, 145.88765, 145.88309, 145.8686 , 145.90535,\n       145.79802, 145.63277, 145.73546, 145.88545, 145.80687, 145.87782,\n       145.81328, 145.74689, 145.76532, 146.59389, 145.62363, 145.66489,\n       145.54094, 145.48001, 145.4125 , 145.32181, 145.46033, 145.3697 ,\n       145.2993 , 145.46347, 145.52838, 145.61986, 145.5864 , 146.10654,\n       146.54851, 146.31183, 146.29903, 146.61267, 146.47269, 146.23853,\n       146.51338, 146.56734, 145.55075, 145.58858, 145.56082, 146.23091,\n       146.22769, 146.24933, 145.69202, 146.12682, 146.06894, 146.2166 ,\n       146.46828, 146.41429, 146.62735, 146.46555, 146.67267, 146.5115 ,\n       146.56155, 145.58855, 146.39082, 146.33511, 146.43759, 145.71982,\n       145.6793 , 145.77908, 145.63249, 145.60204, 145.6054 , 145.56114,\n       145.5198 , 145.54143, 145.46031, 145.34674, 145.28966, 145.28944,\n       145.26875, 145.57275, 145.63557, 145.67822, 146.39017, 146.38783,\n...\n       147.69923, 147.90083, 147.96477, 148.14348, 148.02835, 147.90723,\n       147.77087, 147.8108 , 147.97171, 147.72343, 146.30946, 146.21602,\n       147.39684, 146.37997, 146.60793, 146.56194, 146.6224 , 146.5918 ,\n       146.56328, 146.53462, 146.5808 , 147.00911, 146.28668, 146.38503,\n       146.37201, 146.32549, 146.36899, 146.37764, 146.85728, 145.87483,\n       146.1643 , 146.18391, 146.39412, 146.3155 , 146.31705, 146.33295,\n       146.48418, 146.49727, 146.6232 , 147.00233, 147.02397, 146.99678,\n       146.99535, 146.98616, 146.90967, 146.96208, 146.80684, 147.10713,\n       146.78923, 146.47   , 146.50873, 146.62814, 146.51836, 146.5004 ,\n       146.62518, 145.61536, 146.74213, 146.49141, 146.59415, 146.50864,\n       146.64227, 146.48729, 146.05139, 145.5999 , 146.58469, 146.26138,\n       146.66893, 146.65904, 146.8501 , 147.04012, 146.8955 , 146.64272,\n       146.95453, 146.4743 , 146.53001, 146.94609, 146.98328, 146.91466,\n       146.5447 , 147.07216, 146.55539, 146.69072, 146.68694, 146.65994,\n       146.61472, 146.74748, 145.84705, 145.85425, 146.44633, 146.42802,\n       146.48172, 146.49844, 146.49208, 146.48514, 146.47159, 146.37614,\n       146.34831, 146.42378, 146.44463, 146.4135 , 147.09398, 147.09981,\n       147.1228 , 146.67813, 146.67542, 146.65483, 146.87567, 147.00366,\n       146.72874, 146.671  , 145.57736, 145.61763, 145.59996],\n      dtype=float32)</pre></li><li>area(station)float328.743 8.05 24.13 ... 1.76 4.988long_name :station areaunits :km^2standard_name :area<pre>array([8.74264240e+00, 8.04953766e+00, 2.41292725e+01, 1.15444698e+01,\n       1.48703051e+01, 1.13882227e+01, 2.03471794e+01, 2.85696564e+01,\n       2.99010849e+01, 1.07939901e+01, 2.55833683e+01, 1.69574585e+01,\n       1.20487185e+01, 2.63328037e+01, 2.36108913e+01, 6.97706556e+00,\n       2.22069759e+01, 3.02010384e+01, 1.95261497e+01, 1.47493753e+01,\n       1.03170156e+01, 2.31804771e+01, 2.01167450e+01, 2.09635601e+01,\n       1.19352131e+01, 1.67128429e+01, 9.30091000e+00, 1.80477524e+01,\n       6.29598665e+00, 7.82678986e+00, 3.79344845e+00, 4.03340101e+00,\n       2.13854051e+00, 1.14826517e+01, 6.36217165e+00, 3.22781444e+00,\n       8.10380077e+00, 1.10916786e+01, 1.11773901e+01, 8.82636738e+00,\n       1.02675972e+01, 7.38301239e+01, 5.59130745e+01, 6.63101425e+01,\n       5.00592957e+01, 5.95034599e+01, 9.46557770e+01, 4.62686958e+01,\n       6.02089233e+01, 2.90027828e+01, 8.04257355e+01, 7.60305939e+01,\n       7.20957108e+01, 3.77609901e+01, 6.03701935e+01, 4.43344460e+01,\n       2.97676086e+01, 4.08927917e+01, 1.33005737e+02, 7.74885178e+01,\n       9.13805389e+01, 5.68068733e+01, 6.57058792e+01, 4.17661247e+01,\n       6.57868576e+01, 1.34466064e+02, 3.27444420e+01, 9.36494980e+01,\n       7.36653709e+00, 7.15111685e+00, 4.17642927e+00, 1.22620497e+01,\n       4.99790192e+01, 2.93087673e+01, 2.61270180e+01, 2.71608868e+01,\n       2.65038657e+00, 6.68782349e+01, 8.03473949e+00, 3.01680851e+01,\n...\n       3.27399230e+00, 5.20085357e-02, 1.30760312e+00, 3.78825784e+00,\n       1.91876564e+01, 9.14414883e+00, 4.55969667e+00, 2.69088554e+00,\n       2.89496613e+01, 1.54010344e+01, 1.53724031e+01, 6.27398777e+00,\n       1.91951656e+01, 3.99174919e+01, 1.82449081e+02, 2.85572529e+00,\n       1.27389126e+01, 6.38944588e+01, 1.40638018e+01, 6.24922705e+00,\n       1.58865681e+01, 3.07296109e+00, 1.72298004e+02, 3.98486948e+00,\n       6.46440792e+00, 6.30638075e+00, 4.01565971e+01, 5.16905355e+00,\n       1.60983715e+01, 7.91153669e+00, 1.53524078e+02, 2.27602577e+01,\n       1.12519426e+01, 3.58527327e+00, 4.85922852e+01, 5.92527885e+01,\n       4.52961235e+01, 1.80442352e+01, 6.32809563e+01, 3.66307220e+01,\n       2.05543995e+00, 3.26414299e+00, 6.10807133e+00, 4.30361710e+01,\n       1.78973427e+01, 4.45870514e+01, 5.17808266e+01, 1.05494299e+01,\n       3.23782043e+01, 1.57228680e+01, 6.67126608e+00, 3.32986908e+01,\n       1.70114079e+01, 1.83375323e+00, 2.42743516e+00, 4.89723778e+00,\n       9.67607689e+00, 7.38988495e+00, 1.44319224e+00, 8.16402912e+00,\n       2.63495426e+01, 5.74557781e+00, 5.29048777e+00, 3.75785398e+00,\n       3.47913098e+00, 1.40595894e+01, 2.20178819e+00, 1.72933400e+00,\n       9.82884026e+00, 9.44268715e-04, 5.00415192e+01, 1.87282810e+01,\n       1.26958704e+01, 9.27362633e+00, 1.88401937e+00, 7.25890493e+00,\n       3.35341191e+00, 1.76042402e+00, 4.98821402e+00], dtype=float32)</pre></li></ul></li><li>Indexes: (5)<ul><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2000-11-15 23:00:00', '2000-11-16 23:00:00',\n               '2000-11-17 23:00:00', '2000-11-18 23:00:00',\n               '2000-11-19 23:00:00', '2000-11-20 23:00:00',\n               '2000-11-21 23:00:00', '2000-11-22 23:00:00',\n               '2000-11-23 23:00:00', '2000-11-24 23:00:00',\n               ...\n               '2023-11-01 23:00:00', '2023-11-02 23:00:00',\n               '2023-11-03 23:00:00', '2023-11-04 23:00:00',\n               '2023-11-05 23:00:00', '2023-11-06 23:00:00',\n               '2023-11-07 23:00:00', '2023-11-08 23:00:00',\n               '2023-11-09 23:00:00', '2023-11-10 23:00:00'],\n              dtype='datetime64[ns]', name='time', length=8396, freq=None))</pre></li><li>stationPandasIndex<pre>PandasIndex(Index([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n       ...\n       554, 555, 556, 557, 558, 559, 560, 561, 562, 563],\n      dtype='int64', name='station', length=563))</pre></li><li>ens_memberPandasIndex<pre>PandasIndex(Index([1], dtype='int64', name='ens_member'))</pre></li><li>lead_timePandasIndex<pre>PandasIndex(Index([0], dtype='int32', name='lead_time'))</pre></li><li>station_idPandasIndex<pre>PandasIndex(Index(['18594010', '19629011', '18562015', '18562003', '18562002', '18562020',\n       '18562005', '18562007', '18562008', '18562012',\n       ...\n       '32005971', '32139003', '32139004', '10005071', '10000541', '10008261',\n       '10565028', '28286670', '28294676', '28294677'],\n      dtype='object', name='station_id', length=563))</pre></li></ul></li><li>Attributes: (8)title :not providedinstitution :not providedcatchment :not providedsource :not providedcomment :not providedhistory :not providedSTF_convention_version :2.0STF_nc_spec :https://github.com/csiro-hydroinformatics/efts/blob/d7d43a995fb5e459bcb894e09b7bb89de03e285c/docs/netcdf_for_water_forecasting.md</li></ul> In\u00a0[48]: Copied! <pre>d_tmp = d.copy()\n</pre> d_tmp = d.copy() In\u00a0[49]: Copied! <pre>d_tmp.station\n</pre> d_tmp.station Out[49]: <pre>&lt;xarray.DataArray 'station' (station: 563)&gt; Size: 5kB\narray([  1,   2,   3, ..., 561, 562, 563])\nCoordinates:\n  * station     (station) int64 5kB 1 2 3 4 5 6 7 ... 558 559 560 561 562 563\n  * station_id  (station) &lt;U8 18kB '18594010' '19629011' ... '28294677'</pre>xarray.DataArray'station'<ul><li>station: 563</li></ul><ul><li>1 2 3 4 5 6 7 8 9 10 11 ... 554 555 556 557 558 559 560 561 562 563<pre>array([  1,   2,   3, ..., 561, 562, 563])</pre></li><li>Coordinates: (2)<ul><li>station(station)int641 2 3 4 5 6 ... 559 560 561 562 563<pre>array([  1,   2,   3, ..., 561, 562, 563])</pre></li><li>station_id(station)&lt;U8'18594010' ... '28294677'long_name :station or node identification code<pre>array(['18594010', '19629011', '18562015', ..., '28286670', '28294676',\n       '28294677'], dtype='&lt;U8')</pre></li></ul></li><li>Indexes: (2)<ul><li>stationPandasIndex<pre>PandasIndex(Index([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n       ...\n       554, 555, 556, 557, 558, 559, 560, 561, 562, 563],\n      dtype='int64', name='station', length=563))</pre></li><li>station_idPandasIndex<pre>PandasIndex(Index(['18594010', '19629011', '18562015', '18562003', '18562002', '18562020',\n       '18562005', '18562007', '18562008', '18562012',\n       ...\n       '32005971', '32139003', '32139004', '10005071', '10000541', '10008261',\n       '10565028', '28286670', '28294676', '28294677'],\n      dtype='object', name='station_id', length=563))</pre></li></ul></li><li>Attributes: (0)</li></ul> In\u00a0[50]: Copied! <pre>da.station\n</pre> da.station Out[50]: <pre>&lt;xarray.DataArray 'station' (station: 563)&gt; Size: 2kB\narray([  1,   2,   3, ..., 561, 562, 563], dtype=int32)\nCoordinates:\n  * station  (station) int32 2kB 1 2 3 4 5 6 7 8 ... 557 558 559 560 561 562 563</pre>xarray.DataArray'station'<ul><li>station: 563</li></ul><ul><li>1 2 3 4 5 6 7 8 9 10 11 ... 554 555 556 557 558 559 560 561 562 563<pre>array([  1,   2,   3, ..., 561, 562, 563], dtype=int32)</pre></li><li>Coordinates: (1)<ul><li>station(station)int321 2 3 4 5 6 ... 559 560 561 562 563<pre>array([  1,   2,   3, ..., 561, 562, 563], dtype=int32)</pre></li></ul></li><li>Indexes: (1)<ul><li>stationPandasIndex<pre>PandasIndex(Index([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n       ...\n       554, 555, 556, 557, 558, 559, 560, 561, 562, 563],\n      dtype='int32', name='station', length=563))</pre></li></ul></li><li>Attributes: (0)</li></ul> In\u00a0[51]: Copied! <pre>da = da.assign_coords(d_tmp.station.coords)\n</pre> da = da.assign_coords(d_tmp.station.coords) <pre>\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[51], line 1\n----&gt; 1 da = da.assign_coords(d_tmp.station.coords)\n\nFile ~/src/efts-io/.venv/lib/python3.12/site-packages/xarray/core/common.py:645, in DataWithCoords.assign_coords(self, coords, **coords_kwargs)\n    642 else:\n    643     results = self._calc_assign_results(coords_combined)\n--&gt; 645 data.coords.update(results)\n    646 return data\n\nFile ~/src/efts-io/.venv/lib/python3.12/site-packages/xarray/core/coordinates.py:554, in Coordinates.update(self, other)\n    546 # Discard original indexed coordinates prior to merge allows to:\n    547 # - fail early if the new coordinates don't preserve the integrity of existing\n    548 #   multi-coordinate indexes\n    549 # - drop &amp; replace coordinates without alignment (note: we must keep indexed\n    550 #   coordinates extracted from the DataArray objects passed as values to\n    551 #   `other` - if any - as those are still used for aligning the old/new coordinates)\n    552 coords_to_align = drop_indexed_coords(set(other_coords) &amp; set(other), self)\n--&gt; 554 coords, indexes = merge_coords(\n    555     [coords_to_align, other_coords],\n    556     priority_arg=1,\n    557     indexes=coords_to_align.xindexes,\n    558 )\n    560 # special case for PandasMultiIndex: updating only its dimension coordinate\n    561 # is still allowed but depreciated.\n    562 # It is the only case where we need to actually drop coordinates here (multi-index levels)\n    563 # TODO: remove when removing PandasMultiIndex's dimension coordinate.\n    564 self._drop_coords(self._names - coords_to_align._names)\n\nFile ~/src/efts-io/.venv/lib/python3.12/site-packages/xarray/core/merge.py:556, in merge_coords(objects, compat, join, priority_arg, indexes, fill_value)\n    554 _assert_compat_valid(compat)\n    555 coerced = coerce_pandas_values(objects)\n--&gt; 556 aligned = deep_align(\n    557     coerced, join=join, copy=False, indexes=indexes, fill_value=fill_value\n    558 )\n    559 collected = collect_variables_and_indexes(aligned, indexes=indexes)\n    560 prioritized = _get_priority_vars_and_indexes(aligned, priority_arg, compat=compat)\n\nFile ~/src/efts-io/.venv/lib/python3.12/site-packages/xarray/core/alignment.py:946, in deep_align(objects, join, copy, indexes, exclude, raise_on_invalid, fill_value)\n    943     else:\n    944         out.append(variables)\n--&gt; 946 aligned = align(\n    947     *targets,\n    948     join=join,\n    949     copy=copy,\n    950     indexes=indexes,\n    951     exclude=exclude,\n    952     fill_value=fill_value,\n    953 )\n    955 for position, key, aligned_obj in zip(positions, keys, aligned):\n    956     if key is no_key:\n\nFile ~/src/efts-io/.venv/lib/python3.12/site-packages/xarray/core/alignment.py:882, in align(join, copy, indexes, exclude, fill_value, *objects)\n    686 \"\"\"\n    687 Given any number of Dataset and/or DataArray objects, returns new\n    688 objects with aligned indexes and dimension sizes.\n   (...)\n    872 \n    873 \"\"\"\n    874 aligner = Aligner(\n    875     objects,\n    876     join=join,\n   (...)\n    880     fill_value=fill_value,\n    881 )\n--&gt; 882 aligner.align()\n    883 return aligner.results\n\nFile ~/src/efts-io/.venv/lib/python3.12/site-packages/xarray/core/alignment.py:573, in Aligner.align(self)\n    571 self.find_matching_indexes()\n    572 self.find_matching_unindexed_dims()\n--&gt; 573 self.assert_no_index_conflict()\n    574 self.align_indexes()\n    575 self.assert_unindexed_dim_sizes_equal()\n\nFile ~/src/efts-io/.venv/lib/python3.12/site-packages/xarray/core/alignment.py:318, in Aligner.assert_no_index_conflict(self)\n    314 if dup:\n    315     items_msg = \", \".join(\n    316         f\"{k!r} ({v} conflicting indexes)\" for k, v in dup.items()\n    317     )\n--&gt; 318     raise ValueError(\n    319         \"cannot re-index or align objects with conflicting indexes found for \"\n    320         f\"the following {msg}: {items_msg}\\n\"\n    321         \"Conflicting indexes may occur when\\n\"\n    322         \"- they relate to different sets of coordinate and/or dimension names\\n\"\n    323         \"- they don't have the same type\\n\"\n    324         \"- they may be used to reindex data along common dimensions\"\n    325     )\n\nValueError: cannot re-index or align objects with conflicting indexes found for the following dimensions: 'station' (2 conflicting indexes)\nConflicting indexes may occur when\n- they relate to different sets of coordinate and/or dimension names\n- they don't have the same type\n- they may be used to reindex data along common dimensions</pre> In\u00a0[\u00a0]: Copied! <pre>d_tmp['rain_obs'] = da\n</pre> d_tmp['rain_obs'] = da In\u00a0[\u00a0]: Copied! <pre>d_tmp\n</pre> d_tmp <p>There is a DataArray.rename method to rename coordinates, but since we also have a change of values for the <code>station</code> and <code>station_id</code> coordinates, we need to do more work anyway.</p> In\u00a0[52]: Copied! <pre># make sure we manipulate the 4D dataset: do not assume a certain order in the dimensions:\ncoordinates_mapping = {\n    \"time\": \"time\",\n    \"station\": \"station_id\",\n    \"ens_member\": \"ens_member\",\n    \"lead_time\": \"lead_time\",\n}\nlist(coordinates_mapping.keys())\n</pre> # make sure we manipulate the 4D dataset: do not assume a certain order in the dimensions: coordinates_mapping = {     \"time\": \"time\",     \"station\": \"station_id\",     \"ens_member\": \"ens_member\",     \"lead_time\": \"lead_time\", } list(coordinates_mapping.keys()) Out[52]: <pre>['time', 'station', 'ens_member', 'lead_time']</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[53]: Copied! <pre>rain_obs = rain_cfdecode.rain_obs\nrain_obs\n</pre> rain_obs = rain_cfdecode.rain_obs rain_obs Out[53]: <pre>&lt;xarray.DataArray 'rain_obs' (time: 8396, ens_member: 1, station: 563,\n                              lead_time: 1)&gt; Size: 19MB\n[4726948 values with dtype=float32]\nCoordinates:\n  * time        (time) int32 34kB 1 2 3 4 5 6 ... 8391 8392 8393 8394 8395 8396\n  * station     (station) int32 2kB 1 2 3 4 5 6 7 ... 558 559 560 561 562 563\n  * lead_time   (lead_time) int32 4B 0\n  * ens_member  (ens_member) int32 4B 1\nAttributes:\n    standard_name:         rain_obs\n    long_name:             observed rainfall\n    units:                 mm\n    type:                  2.0\n    type_description:      accumulated over the preceding interval\n    dat_type:              der\n    dat_type_description:  derived (from observations)\n    location_type:         area</pre>xarray.DataArray'rain_obs'<ul><li>time: 8396</li><li>ens_member: 1</li><li>station: 563</li><li>lead_time: 1</li></ul><ul><li>...<pre>[4726948 values with dtype=float32]</pre></li><li>Coordinates: (4)<ul><li>time(time)int321 2 3 4 5 ... 8393 8394 8395 8396standard_name :timelong_name :timetime_standard :UTCaxis :tunits :days since 2000-11-14 23:00:00.0 +0000<pre>array([   1,    2,    3, ..., 8394, 8395, 8396], dtype=int32)</pre></li><li>station(station)int321 2 3 4 5 6 ... 559 560 561 562 563<pre>array([  1,   2,   3, ..., 561, 562, 563], dtype=int32)</pre></li><li>lead_time(lead_time)int320standard_name :lead timelong_name :forecast lead timeaxis :vunits :days since time<pre>array([0], dtype=int32)</pre></li><li>ens_member(ens_member)int321standard_name :ens_memberlong_name :ensemble memberunits :member idaxis :u<pre>array([1], dtype=int32)</pre></li></ul></li><li>Indexes: (4)<ul><li>timePandasIndex<pre>PandasIndex(Index([   1,    2,    3,    4,    5,    6,    7,    8,    9,   10,\n       ...\n       8387, 8388, 8389, 8390, 8391, 8392, 8393, 8394, 8395, 8396],\n      dtype='int32', name='time', length=8396))</pre></li><li>stationPandasIndex<pre>PandasIndex(Index([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n       ...\n       554, 555, 556, 557, 558, 559, 560, 561, 562, 563],\n      dtype='int32', name='station', length=563))</pre></li><li>lead_timePandasIndex<pre>PandasIndex(Index([0], dtype='int32', name='lead_time'))</pre></li><li>ens_memberPandasIndex<pre>PandasIndex(Index([1], dtype='int32', name='ens_member'))</pre></li></ul></li><li>Attributes: (8)standard_name :rain_obslong_name :observed rainfallunits :mmtype :2.0type_description :accumulated over the preceding intervaldat_type :derdat_type_description :derived (from observations)location_type :area</li></ul> In\u00a0[54]: Copied! <pre>d.station_id.attrs\n</pre> d.station_id.attrs Out[54]: <pre>{'long_name': 'station or node identification code'}</pre> In\u00a0[55]: Copied! <pre>axis = \"hours since 2010-08-01 13:00:00 +0000\"\n</pre> axis = \"hours since 2010-08-01 13:00:00 +0000\" In\u00a0[56]: Copied! <pre>decod.decode(\n</pre> decod.decode( <pre>\n  Cell In[56], line 1\n    decod.decode(\n                 ^\nSyntaxError: incomplete input\n</pre> In\u00a0[\u00a0]: Copied! <pre>import cftime\n</pre> import cftime In\u00a0[\u00a0]: Copied! <pre>cftime.time2index\n</pre> cftime.time2index"},{"location":"nb/design_rationale/#design-rationale","title":"Design rationale\u00b6","text":"<p>The netCDF STF 2.0 compliant format is such that a file loaded from Python via <code>xarray</code> is not the most convenient data model for users.</p> <p>This notebook illustrates interactively the behaviors, and informs the design choices made to reconcile the <code>xarray</code> view with the on-disk representation.</p>"},{"location":"nb/design_rationale/#loading-an-existing-reference-netcdf-file","title":"Loading an existing reference netCDF file\u00b6","text":"<p>A file was created using (probably) a Matlab implementation of STF data handling and I/O. Let's load it via <code>xarray</code> as well as the <code>netCDF4</code> package, as we are not sure which will be most adequate for <code>efts-io</code> for saving/loading operations.</p>"},{"location":"nb/design_rationale/#xarray-read","title":"xarray read\u00b6","text":""},{"location":"nb/design_rationale/#netcdf4-read","title":"netCDF4 read\u00b6","text":""},{"location":"nb/design_rationale/#requirements","title":"Requirements\u00b6","text":""},{"location":"nb/design_rationale/#desired-in-memory-representation","title":"Desired in-memory representation\u00b6","text":"<p>See this discussion for background.</p> <p>We assume that an \"intuitive\" data representation in an xarray dataset would have the following characteristics:</p> <ul> <li>The <code>time</code> coordinate has values with python representations <code>np.datetime64</code> or similar</li> <li>A <code>station_id</code> coordinate has values as strings rather than bytes, so that slicing can be done with statements such as <code>data.sel(station_id=\"407113A\")</code>. The STF representation is such that <code>station</code> is a dimension/coordinate, not <code>station_id</code></li> <li>In the example case loaded, the variable datatypes is 32-bits <code>np.float32</code> rather than 64 bits <code>np.float</code>. The latter is probably more convenient in most use cases we can anticipate. However we may want to consider keeping a 32 bits representation: ensemble forecasting and modelling methods can be RAM-hungry even with 2024 typical machine setups.</li> <li>coordinate data is in type <code>int32</code>. Memory footprint is not a consideration, we may want to change is to 64 bits, or not, based on other factors.</li> <li>There should be a coordinate named \"realisation\" (or U.S. \"realization\"??) rather than \"ens_member\"</li> </ul>"},{"location":"nb/design_rationale/#stf-20-compliance","title":"STF 2.0 compliance\u00b6","text":"<p>It is imperative to be able to export the in-memory xarray representation to a <code>netCDF</code> file that complies with documented conventions and is readable by existing toolsets in <code>Matlab</code>, <code>C++</code> or even <code>Fortran</code>. A key question is whether we can use <code>xarray.to_netcdf</code> or whether we need to use the lower level package <code>netCDF4</code> to achieve that.</p>"},{"location":"nb/design_rationale/#implementation","title":"Implementation\u00b6","text":"<p>This notebook will illustrate the various steps taken to bridge the gap between the on-disk and in-memory representations.</p>"},{"location":"nb/design_rationale/#reading-from-disk","title":"Reading from disk\u00b6","text":""},{"location":"nb/design_rationale/#time","title":"time\u00b6","text":"<p>For background in issue https://jira.csiro.au/browse/WIRADA-635. We cannot have xarray automagically decoding this axis, so we need to do the work manually, but using as much as possible work already done. Not sure how I had figured out about <code>CFDatetimeCoder</code>, but:</p>"},{"location":"nb/design_rationale/#station_id","title":"station_id\u00b6","text":""},{"location":"nb/design_rationale/#station_name","title":"station_name\u00b6","text":""},{"location":"nb/design_rationale/#creating-a-new-dataset","title":"creating a new dataset\u00b6","text":"<p>The package already includes a function to create high level <code>xarray</code></p>"},{"location":"nb/design_rationale/#time-axis","title":"time axis\u00b6","text":""},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li> efts_io<ul> <li> attributes</li> <li> cli</li> <li> conventions</li> <li> debug</li> <li> dimensions</li> <li> helpers</li> <li> variables</li> <li> wrapper</li> </ul> </li> </ul>"},{"location":"reference/efts_io/","title":"efts_io","text":""},{"location":"reference/efts_io/#efts_io","title":"efts_io","text":"<p>efts-io package.</p> <p>Ensemble forecast time series</p>"},{"location":"reference/efts_io/attributes/","title":"efts_io.attributes","text":""},{"location":"reference/efts_io/attributes/#efts_io.attributes","title":"attributes","text":""},{"location":"reference/efts_io/attributes/#efts_io.attributes.create_var_attribute_definition","title":"create_var_attribute_definition","text":"<pre><code>create_var_attribute_definition(\n    data_type_code: int = 2,\n    type_description: str = \"accumulated over the preceding interval\",\n    dat_type: str = \"der\",\n    dat_type_description: str = \"AWAP data interpolated from observations\",\n    location_type: str = \"Point\",\n)\n</code></pre> <p>Create variable attribute definition.</p> Source code in <code>src/efts_io/attributes.py</code> <pre><code>def create_var_attribute_definition(\n    data_type_code: int = 2,\n    type_description: str = \"accumulated over the preceding interval\",\n    dat_type: str = \"der\",\n    dat_type_description: str = \"AWAP data interpolated from observations\",\n    location_type: str = \"Point\",\n):\n    \"\"\"Create variable attribute definition.\"\"\"\n    return {\n        \"type\": data_type_code,\n        \"type_description\": type_description,\n        \"dat_type\": dat_type,\n        \"dat_type_description\": dat_type_description,\n        \"location_type\": location_type,\n    }\n</code></pre>"},{"location":"reference/efts_io/cli/","title":"efts_io.cli","text":""},{"location":"reference/efts_io/cli/#efts_io.cli","title":"cli","text":"<p>Module that contains the command line application.</p>"},{"location":"reference/efts_io/cli/#efts_io.cli.get_parser","title":"get_parser","text":"<pre><code>get_parser() -&gt; ArgumentParser\n</code></pre> <p>Return the CLI argument parser.</p> <p>Returns:</p> <ul> <li> <code>ArgumentParser</code>           \u2013            <p>An argparse parser.</p> </li> </ul> Source code in <code>src/efts_io/cli.py</code> <pre><code>def get_parser() -&gt; argparse.ArgumentParser:\n    \"\"\"Return the CLI argument parser.\n\n    Returns:\n        An argparse parser.\n    \"\"\"\n    parser = argparse.ArgumentParser(prog=\"efts\")\n    parser.add_argument(\"-V\", \"--version\", action=\"version\", version=f\"%(prog)s {debug.get_version()}\")\n    parser.add_argument(\"--debug-info\", action=_DebugInfo, help=\"Print debug information.\")\n    return parser\n</code></pre>"},{"location":"reference/efts_io/cli/#efts_io.cli.main","title":"main","text":"<pre><code>main(args: list[str] | None = None) -&gt; int\n</code></pre> <p>Run the main program.</p> <p>This function is executed when you type <code>efts</code> or <code>python -m efts_io</code>.</p> <p>Parameters:</p> <ul> <li> <code>args</code>               (<code>list[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>Arguments passed from the command line.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>An exit code.</p> </li> </ul> Source code in <code>src/efts_io/cli.py</code> <pre><code>def main(args: list[str] | None = None) -&gt; int:\n    \"\"\"Run the main program.\n\n    This function is executed when you type `efts` or `python -m efts_io`.\n\n    Parameters:\n        args: Arguments passed from the command line.\n\n    Returns:\n        An exit code.\n    \"\"\"\n    parser = get_parser()\n    opts = parser.parse_args(args=args)\n    print(opts)\n    return 0\n</code></pre>"},{"location":"reference/efts_io/conventions/","title":"efts_io.conventions","text":""},{"location":"reference/efts_io/conventions/#efts_io.conventions","title":"conventions","text":"<p>Naming conventions for the EFTS netCDF file format.</p>"},{"location":"reference/efts_io/conventions/#efts_io.conventions.ConvertibleToTimestamp","title":"ConvertibleToTimestamp  <code>module-attribute</code>","text":"<pre><code>ConvertibleToTimestamp = Union[\n    str, datetime, datetime64, Timestamp\n]\n</code></pre> <p>Definition of a 'type' for type hints.</p>"},{"location":"reference/efts_io/conventions/#efts_io.conventions.check_index_found","title":"check_index_found","text":"<pre><code>check_index_found(\n    index_id: Optional[int],\n    identifier: str,\n    dimension_id: str,\n) -&gt; None\n</code></pre> <p>Helper function to check that a value (index) was is indeed found in the dimension.</p> Source code in <code>src/efts_io/conventions.py</code> <pre><code>def check_index_found(\n    index_id: Optional[int],\n    identifier: str,\n    dimension_id: str,\n) -&gt; None:\n    \"\"\"Helper function to check that a value (index) was is indeed found in the dimension.\"\"\"\n    # return isinstance(index_id, np.int64)\n    if index_id is None:\n        raise ValueError(\n            f\"identifier '{identifier}' not found in the dimension '{dimension_id}'\",\n        )\n</code></pre>"},{"location":"reference/efts_io/conventions/#efts_io.conventions.get_default_dim_order","title":"get_default_dim_order","text":"<pre><code>get_default_dim_order() -&gt; List[str]\n</code></pre> <p>Default order of dimensions in the netCDF file.</p> <p>Returns:</p> <ul> <li> <code>List[str]</code>           \u2013            <p>List[str]: dimension names: [lead_time, stations, ensemble_member, time]</p> </li> </ul> Source code in <code>src/efts_io/conventions.py</code> <pre><code>def get_default_dim_order() -&gt; List[str]:\n    \"\"\"Default order of dimensions in the netCDF file.\n\n    Returns:\n        List[str]: dimension names: [lead_time, stations, ensemble_member, time]\n    \"\"\"\n    return [\n        LEAD_TIME_DIMNAME,\n        STATION_DIMNAME,\n        ENS_MEMBER_DIMNAME,\n        TIME_DIMNAME,\n    ]\n</code></pre>"},{"location":"reference/efts_io/debug/","title":"efts_io.debug","text":""},{"location":"reference/efts_io/debug/#efts_io.debug","title":"debug","text":"<p>Debugging utilities.</p>"},{"location":"reference/efts_io/debug/#efts_io.debug.Environment","title":"Environment  <code>dataclass</code>","text":"<pre><code>Environment(\n    interpreter_name: str,\n    interpreter_version: str,\n    interpreter_path: str,\n    platform: str,\n    packages: list[Package],\n    variables: list[Variable],\n)\n</code></pre> <p>Dataclass to store environment information.</p>"},{"location":"reference/efts_io/debug/#efts_io.debug.Environment.interpreter_name","title":"interpreter_name  <code>instance-attribute</code>","text":"<pre><code>interpreter_name: str\n</code></pre> <p>Python interpreter name.</p>"},{"location":"reference/efts_io/debug/#efts_io.debug.Environment.interpreter_path","title":"interpreter_path  <code>instance-attribute</code>","text":"<pre><code>interpreter_path: str\n</code></pre> <p>Path to Python executable.</p>"},{"location":"reference/efts_io/debug/#efts_io.debug.Environment.interpreter_version","title":"interpreter_version  <code>instance-attribute</code>","text":"<pre><code>interpreter_version: str\n</code></pre> <p>Python interpreter version.</p>"},{"location":"reference/efts_io/debug/#efts_io.debug.Environment.packages","title":"packages  <code>instance-attribute</code>","text":"<pre><code>packages: list[Package]\n</code></pre> <p>Installed packages.</p>"},{"location":"reference/efts_io/debug/#efts_io.debug.Environment.platform","title":"platform  <code>instance-attribute</code>","text":"<pre><code>platform: str\n</code></pre> <p>Operating System.</p>"},{"location":"reference/efts_io/debug/#efts_io.debug.Environment.variables","title":"variables  <code>instance-attribute</code>","text":"<pre><code>variables: list[Variable]\n</code></pre> <p>Environment variables.</p>"},{"location":"reference/efts_io/debug/#efts_io.debug.Package","title":"Package  <code>dataclass</code>","text":"<pre><code>Package(name: str, version: str)\n</code></pre> <p>Dataclass describing a Python package.</p>"},{"location":"reference/efts_io/debug/#efts_io.debug.Package.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre> <p>Package name.</p>"},{"location":"reference/efts_io/debug/#efts_io.debug.Package.version","title":"version  <code>instance-attribute</code>","text":"<pre><code>version: str\n</code></pre> <p>Package version.</p>"},{"location":"reference/efts_io/debug/#efts_io.debug.Variable","title":"Variable  <code>dataclass</code>","text":"<pre><code>Variable(name: str, value: str)\n</code></pre> <p>Dataclass describing an environment variable.</p>"},{"location":"reference/efts_io/debug/#efts_io.debug.Variable.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre> <p>Variable name.</p>"},{"location":"reference/efts_io/debug/#efts_io.debug.Variable.value","title":"value  <code>instance-attribute</code>","text":"<pre><code>value: str\n</code></pre> <p>Variable value.</p>"},{"location":"reference/efts_io/debug/#efts_io.debug.get_debug_info","title":"get_debug_info","text":"<pre><code>get_debug_info() -&gt; Environment\n</code></pre> <p>Get debug/environment information.</p> <p>Returns:</p> <ul> <li> <code>Environment</code>           \u2013            <p>Environment information.</p> </li> </ul> Source code in <code>src/efts_io/debug.py</code> <pre><code>def get_debug_info() -&gt; Environment:\n    \"\"\"Get debug/environment information.\n\n    Returns:\n        Environment information.\n    \"\"\"\n    py_name, py_version = _interpreter_name_version()\n    packages = [\"efts-io\"]\n    variables = [\"PYTHONPATH\", *[var for var in os.environ if var.startswith(\"EFTS_IO\")]]\n    return Environment(\n        interpreter_name=py_name,\n        interpreter_version=py_version,\n        interpreter_path=sys.executable,\n        platform=platform.platform(),\n        variables=[Variable(var, val) for var in variables if (val := os.getenv(var))],\n        packages=[Package(pkg, get_version(pkg)) for pkg in packages],\n    )\n</code></pre>"},{"location":"reference/efts_io/debug/#efts_io.debug.get_version","title":"get_version","text":"<pre><code>get_version(dist: str = 'efts-io') -&gt; str\n</code></pre> <p>Get version of the given distribution.</p> <p>Parameters:</p> <ul> <li> <code>dist</code>               (<code>str</code>, default:                   <code>'efts-io'</code> )           \u2013            <p>A distribution name.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>A version number.</p> </li> </ul> Source code in <code>src/efts_io/debug.py</code> <pre><code>def get_version(dist: str = \"efts-io\") -&gt; str:\n    \"\"\"Get version of the given distribution.\n\n    Parameters:\n        dist: A distribution name.\n\n    Returns:\n        A version number.\n    \"\"\"\n    try:\n        return metadata.version(dist)\n    except metadata.PackageNotFoundError:\n        return \"0.0.0\"\n</code></pre>"},{"location":"reference/efts_io/debug/#efts_io.debug.print_debug_info","title":"print_debug_info","text":"<pre><code>print_debug_info() -&gt; None\n</code></pre> <p>Print debug/environment information.</p> Source code in <code>src/efts_io/debug.py</code> <pre><code>def print_debug_info() -&gt; None:\n    \"\"\"Print debug/environment information.\"\"\"\n    info = get_debug_info()\n    print(f\"- __System__: {info.platform}\")\n    print(f\"- __Python__: {info.interpreter_name} {info.interpreter_version} ({info.interpreter_path})\")\n    print(\"- __Environment variables__:\")\n    for var in info.variables:\n        print(f\"  - `{var.name}`: `{var.value}`\")\n    print(\"- __Installed packages__:\")\n    for pkg in info.packages:\n        print(f\"  - `{pkg.name}` v{pkg.version}\")\n</code></pre>"},{"location":"reference/efts_io/dimensions/","title":"efts_io.dimensions","text":""},{"location":"reference/efts_io/dimensions/#efts_io.dimensions","title":"dimensions","text":"<p>Functions to create and manipulate dimensions for netCDF files.</p>"},{"location":"reference/efts_io/dimensions/#efts_io.dimensions.as_naive_timestamp","title":"as_naive_timestamp","text":"<pre><code>as_naive_timestamp(\n    d: Union[datetime, Timestamp]\n) -&gt; Timestamp\n</code></pre> <p>Convert a date-time object to a naive timestamp.</p> Source code in <code>src/efts_io/dimensions.py</code> <pre><code>def as_naive_timestamp(d: Union[datetime, pd.Timestamp]) -&gt; pd.Timestamp:\n    \"\"\"Convert a date-time object to a naive timestamp.\"\"\"\n    return pd.Timestamp(\n        year=d.year,\n        month=d.month,\n        day=d.day,\n        hour=d.hour,\n        minute=d.minute,\n        second=d.second,\n    )\n</code></pre>"},{"location":"reference/efts_io/dimensions/#efts_io.dimensions.check_is_utc","title":"check_is_utc","text":"<pre><code>check_is_utc(d: Any) -&gt; bool\n</code></pre> <p>Check that a date-time is in the UTC time zone.</p> Source code in <code>src/efts_io/dimensions.py</code> <pre><code>def check_is_utc(d: Any) -&gt; bool:\n    \"\"\"Check that a date-time is in the UTC time zone.\"\"\"\n    a = pd.Timestamp(d)\n    if a.tz is None:\n        return True  # ?\n    z = a.tz\n    from datetime import timezone\n\n    return z == timezone.utc\n</code></pre>"},{"location":"reference/efts_io/dimensions/#efts_io.dimensions.create_netcdf_time_axis","title":"create_netcdf_time_axis","text":"<pre><code>create_netcdf_time_axis(\n    d: Any,\n    time_step: str = \"hours since\",\n    tzoffset: Optional[str] = None,\n) -&gt; str\n</code></pre> <p>Create a time axis unit known to work for netCDF.</p> Source code in <code>src/efts_io/dimensions.py</code> <pre><code>def create_netcdf_time_axis(d: Any, time_step: str = \"hours since\", tzoffset: Optional[str] = None) -&gt; str:\n    \"\"\"Create a time axis unit known to work for netCDF.\"\"\"\n    if tzoffset is None:\n        if not check_is_utc(d):\n            raise ValueError(\"date time must have UTC or GMT as time zone\")\n        tzoffset = \"+0000\"\n    return \" \".join([time_step, iso_date_time_str(as_naive_timestamp(d)), tzoffset])\n</code></pre>"},{"location":"reference/efts_io/dimensions/#efts_io.dimensions.create_time_info","title":"create_time_info","text":"<pre><code>create_time_info(\n    start: Any,\n    n: int,\n    time_step: str = \"hours since\",\n    time_step_delta: int = 1,\n    tzoffset: Optional[str] = None,\n) -&gt; Dict[str, Any]\n</code></pre> <p>Helper function to create the definition of the time dimension for use in a netCDF file.</p> Source code in <code>src/efts_io/dimensions.py</code> <pre><code>def create_time_info(\n    start: Any,\n    n: int,\n    time_step: str = \"hours since\",\n    time_step_delta: int = 1,\n    tzoffset: Optional[str] = None,\n) -&gt; Dict[str, Any]:\n    \"\"\"Helper function to create the definition of the time dimension for use in a netCDF file.\"\"\"\n    return {\n        UNITS_ATTR_KEY: create_netcdf_time_axis(\n            d=start,\n            time_step=time_step,\n            tzoffset=tzoffset,\n        ),\n        \"values\": np.arange(0, n) * time_step_delta,\n    }\n</code></pre>"},{"location":"reference/efts_io/dimensions/#efts_io.dimensions.iso_date_time_str","title":"iso_date_time_str","text":"<pre><code>iso_date_time_str(t: Any) -&gt; str\n</code></pre> <p>Convert a date-time object to a string in ISO format, using space as separator.</p> Source code in <code>src/efts_io/dimensions.py</code> <pre><code>def iso_date_time_str(t: Any) -&gt; str:\n    \"\"\"Convert a date-time object to a string in ISO format, using space as separator.\"\"\"\n    return pd.Timestamp(t).isoformat(\" \")\n</code></pre>"},{"location":"reference/efts_io/helpers/","title":"efts_io.helpers","text":""},{"location":"reference/efts_io/helpers/#efts_io.helpers","title":"helpers","text":""},{"location":"reference/efts_io/variables/","title":"efts_io.variables","text":""},{"location":"reference/efts_io/variables/#efts_io.variables","title":"variables","text":"<p>Handling of EFTS netCDF variables definitions.</p>"},{"location":"reference/efts_io/variables/#efts_io.variables.create_efts_variables","title":"create_efts_variables","text":"<pre><code>create_efts_variables(\n    data_var_def: Dict,\n    time_dim_info: Dict,\n    num_stations: int,\n    lead_length: int,\n    ensemble_length: int,\n    optional_vars: Optional[DataFrame],\n    lead_time_tstep: str,\n) -&gt; Dict[str, Any]\n</code></pre> <p>Create netCDF variables according to the definition.</p> Source code in <code>src/efts_io/variables.py</code> <pre><code>def create_efts_variables(\n    data_var_def: Dict,\n    time_dim_info: Dict,\n    num_stations: int,\n    lead_length: int,\n    ensemble_length: int,\n    optional_vars: Optional[pd.DataFrame],\n    lead_time_tstep: str,\n) -&gt; Dict[str, Any]:\n    \"\"\"Create netCDF variables according to the definition.\"\"\"\n    efts_dims = _create_nc_dims(\n        time_dim_info=time_dim_info,\n        num_stations=num_stations,\n        lead_length=lead_length,\n        ensemble_length=ensemble_length,\n    )\n\n    time_dim = efts_dims[\"time_dim\"]\n    lead_time_dim = efts_dims[\"lead_time_dim\"]\n    station_dim = efts_dims[\"station_dim\"]\n    str_dim = efts_dims[\"str_dim\"]\n    ensemble_dim = efts_dims[\"ensemble_dim\"]\n\n    mandatory_var_ncdefs = create_mandatory_vardefs(\n        station_dim,\n        str_dim,\n        ensemble_dim,\n        lead_time_dim,\n        lead_time_tstep,\n    )\n    variables_metadata = mandatory_var_ncdefs\n    if optional_vars is not None:\n        optional_var_ncdefs = create_optional_vardefs(\n            station_dim,\n            vars_def=optional_vars,\n        )\n        # TODO if not native to ncdf4: check name clashes\n        # already_defs = names(variables)\n        variables_metadata = variables_metadata.update(optional_var_ncdefs)\n\n    unknown_dims = [x for x in data_var_def.values() if x[\"dim_type\"] not in [\"2\", \"3\", \"4\"]]\n    if len(unknown_dims) &gt; 0:\n        raise ValueError(\n            \"Invalid dimension specifications for \"\n            + len(unknown_dims)\n            + \" variables. Only supported are characters 2, 3, 4\",\n        )\n\n    variables = {}\n    variables[\"metadatavars\"] = variables_metadata\n\n    data_variables = empty_data_variables(data_var_def, time_dim, lead_time_dim, station_dim, ensemble_dim)\n    variables[\"datavars\"] = data_variables\n\n    return variables\n</code></pre>"},{"location":"reference/efts_io/variables/#efts_io.variables.create_mandatory_vardefs","title":"create_mandatory_vardefs","text":"<pre><code>create_mandatory_vardefs(\n    station_dim: str,\n    str_dim: str,\n    ensemble_dim: str,\n    lead_time_dim: str,\n    lead_time_tstep: str = \"hours\",\n) -&gt; Dict[str, Dict[str, Any]]\n</code></pre> <p>Create mandatory variable definitions.</p> Source code in <code>src/efts_io/variables.py</code> <pre><code>def create_mandatory_vardefs(\n    station_dim: str,\n    str_dim: str,\n    ensemble_dim: str,\n    lead_time_dim: str,\n    lead_time_tstep: str = \"hours\",\n) -&gt; Dict[str, Dict[str, Any]]:\n    \"\"\"Create mandatory variable definitions.\"\"\"\n    # https://github.com/jmp75/efts/blob/107c553045a37e6ef36b2eababf6a299e7883d50/docs/netcdf_for_water_forecasting.md#mandatory-variables\n    # float time(time)\n    # int station_id(station)\n    # char station_name(strLen, station)\n    # int ens_member(ens_member)\n    # float lead_time(lead_time)\n    # float lat (station)\n    # float lon (station)\n    import xarray as xr\n\n    # STATION_DIMNAME,\n    # LEAD_TIME_DIMNAME,\n    # TIME_DIMNAME,\n    # ENS_MEMBER_DIMNAME,\n    # STR_LEN_DIMNAME,\n\n    station_id_variable = xr.Variable(\n        dims=[STATION_DIMNAME],\n        data=station_dim[1],\n        encoding={\"_FillValue\": None},\n        attrs={\n            \"longname\": station_dim[2][\"longname\"],\n            UNITS_ATTR_KEY: \"\",\n            \"missval\": None,\n            \"precision\": \"integer\",\n        },\n    )\n    station_names_dim_variable = xr.Variable(\n        dims=[str_dim[0], STATION_DIMNAME],\n        # That was not intuitive to create this empty array. Not entirely sure this is what we want.\n        data=np.empty_like(\n            prototype=b\"\",\n            shape=(len(str_dim[1]), len(station_dim[1])),\n            dtype=np.bytes_,\n        ),\n        encoding={\"_FillValue\": None},\n        attrs={\n            \"longname\": \"station or node name\",\n            UNITS_ATTR_KEY: \"\",\n            \"missval\": None,\n            \"precision\": \"char\",\n        },\n    )\n    ensemble_member_id_variable = xr.Variable(\n        dims=[ENS_MEMBER_DIMNAME],\n        data=ensemble_dim[1],\n        encoding={\"_FillValue\": None},\n        attrs={\n            \"longname\": ensemble_dim[2][\"longname\"],\n            UNITS_ATTR_KEY: \"\",\n            \"missval\": None,\n            \"precision\": \"integer\",\n        },\n    )\n    lead_time_dim_variable = xr.Variable(\n        dims=[LEAD_TIME_DIMNAME],\n        data=lead_time_dim[1],\n        encoding={\"_FillValue\": None},\n        attrs={\n            \"longname\": lead_time_dim[2][\"longname\"],\n            UNITS_ATTR_KEY: lead_time_tstep + \" since time\",\n            \"missval\": None,\n            \"precision\": \"integer\",\n        },\n    )\n    latitude_dim_variable = xr.Variable(\n        dims=[STATION_DIMNAME],\n        data=np.empty_like(station_dim[1], dtype=float),\n        encoding={\"_FillValue\": -9999.0},\n        attrs={\n            \"longname\": \"latitude\",\n            UNITS_ATTR_KEY: \"degrees north\",\n            \"missval\": -9999.0,\n            \"precision\": \"float\",\n        },\n    )\n    longitude_dim_variable = xr.Variable(\n        dims=[STATION_DIMNAME],\n        data=np.empty_like(station_dim[1], dtype=float),\n        encoding={\"_FillValue\": -9999.0},\n        attrs={\n            \"longname\": \"longitude\",\n            UNITS_ATTR_KEY: \"degrees east\",\n            \"missval\": -9999.0,\n            \"precision\": \"float\",\n        },\n    )\n\n    return {\n        \"station_ids_var\": station_id_variable,\n        \"station_names_var\": station_names_dim_variable,\n        \"ensemble_var\": ensemble_member_id_variable,\n        \"lead_time_var\": lead_time_dim_variable,\n        \"latitude_var\": latitude_dim_variable,\n        \"longitude_var\": longitude_dim_variable,\n    }\n</code></pre>"},{"location":"reference/efts_io/variables/#efts_io.variables.create_optional_vardefs","title":"create_optional_vardefs","text":"<pre><code>create_optional_vardefs(\n    station_dim: str, vars_def: Optional[DataFrame] = None\n) -&gt; Series\n</code></pre> <p>Create optional variable definitions.</p> Source code in <code>src/efts_io/variables.py</code> <pre><code>def create_optional_vardefs(\n    station_dim: str,\n    vars_def: Optional[pd.DataFrame] = None,\n) -&gt; pd.Series:\n    \"\"\"Create optional variable definitions.\"\"\"\n    if vars_def is None:\n        vars_def = default_optional_variable_definitions_v2_0()\n\n    # https://github.com/jmp75/efts/blob/107c553045a37e6ef36b2eababf6a299e7883d50/docs/netcdf_for_water_forecasting.md#mandatory-variables\n    # vars_def$rownum = 1:nrow(vars_def)\n    def f(vd: Dict):  # noqa: ANN202\n        return {\n            \"name\": vd[\"name\"],\n            UNITS_ATTR_KEY: vd[UNITS_ATTR_KEY],\n            \"dim\": list(station_dim),\n            \"missval\": vd[\"missval\"],\n            \"longname\": vd[\"longname\"],\n            \"prec\": vd[\"precision\"],\n        }\n\n    return vars_def.apply(lambda x: f(x), axis=1)\n</code></pre>"},{"location":"reference/efts_io/variables/#efts_io.variables.create_variable_definition","title":"create_variable_definition","text":"<pre><code>create_variable_definition(\n    name: str,\n    longname: str = \"\",\n    units: str = \"mm\",\n    missval: float = -9999.0,\n    precision: str = \"double\",\n    dim_type: str = \"4\",\n    var_attribute: Optional[str] = None,\n) -&gt; dict[str, Any]\n</code></pre> <p>Create a variable definition.</p> Source code in <code>src/efts_io/variables.py</code> <pre><code>def create_variable_definition(\n    name: str,\n    longname: str = \"\",\n    units: str = \"mm\",\n    missval: float = -9999.0,\n    precision: str = \"double\",\n    dim_type: str = \"4\",\n    var_attribute: Optional[str] = None,\n) -&gt; dict[str, Any]:\n    \"\"\"Create a variable definition.\"\"\"\n    if var_attribute is None:\n        var_attribute = create_var_attribute_definition()\n    return {\n        \"name\": name,\n        \"longname\": longname,\n        UNITS_ATTR_KEY: units,\n        \"dim_type\": dim_type,\n        \"missval\": missval,\n        \"precision\": precision,\n        \"attributes\": var_attribute,\n    }\n</code></pre>"},{"location":"reference/efts_io/variables/#efts_io.variables.create_variable_definitions","title":"create_variable_definitions","text":"<pre><code>create_variable_definitions(\n    dframe: DataFrame,\n) -&gt; List[Dict[str, Any]]\n</code></pre> <p>Create variable definitions from a data frame.</p> Source code in <code>src/efts_io/variables.py</code> <pre><code>def create_variable_definitions(dframe: pd.DataFrame) -&gt; List[Dict[str, Any]]:\n    \"\"\"Create variable definitions from a data frame.\"\"\"\n    in_names = dframe.columns\n    non_opt_attr = [\"name\", \"longname\", UNITS_ATTR_KEY, \"missval\", \"precision\", \"dimensions\"]\n    varargs_attr = [x for x in in_names if x not in non_opt_attr]\n\n    def f(var_def: Dict[str, Any]):  # noqa: ANN202\n        return create_variable_definition(\n            name=var_def[\"name\"],\n            longname=var_def[\"longname\"],\n            units=var_def[UNITS_ATTR_KEY],\n            missval=var_def[\"missval\"],\n            precision=var_def[\"precision\"],\n            dim_type=var_def[\"dimensions\"],\n            var_attribute=var_def[varargs_attr],\n        )\n\n    # dframe[['rownum']] = 1:nrow(dframe)\n    # r = plyr::dlply(.data = dframe, .variables = \"rownum\", .fun = f)\n    variables_defs: Dict = dframe.apply(lambda x: f(x), axis=1)\n    res = {v[\"name\"]: v for k, v in variables_defs.items()}\n    return res\n</code></pre>"},{"location":"reference/efts_io/variables/#efts_io.variables.default_optional_variable_definitions_v2_0","title":"default_optional_variable_definitions_v2_0","text":"<pre><code>default_optional_variable_definitions_v2_0() -&gt; DataFrame\n</code></pre> <p>Provide a template definition of optional geolocation variables.</p> Source code in <code>src/efts_io/variables.py</code> <pre><code>def default_optional_variable_definitions_v2_0() -&gt; pd.DataFrame:\n    \"\"\"Provide a template definition of optional geolocation variables.\"\"\"\n    return pd.DataFrame.from_dict(\n        {\n            \"name\": [\"x\", \"y\", AREA_VARNAME, \"elevation\"],\n            \"longname\": [\n                \"easting from the GDA94 datum in MGA Zone 55\",\n                \"northing from the GDA94 datum in MGA Zone 55\",\n                \"catchment area\",\n                \"station elevation above sea level\",\n            ],\n            STANDARD_NAME_ATTR_KEY: [\n                \"northing_GDA94_zone55\",\n                \"easting_GDA94_zone55\",\n                AREA_VARNAME,\n                \"elevation\",\n            ],\n            UNITS_ATTR_KEY: [\"\", \"\", \"km^2\", \"m\"],\n            \"missval\": [np.nan, np.nan, -9999.0, -9999.0],\n            \"precision\": np.repeat(\"float\", 4),\n        },\n    )\n</code></pre>"},{"location":"reference/efts_io/wrapper/","title":"efts_io.wrapper","text":""},{"location":"reference/efts_io/wrapper/#efts_io.wrapper","title":"wrapper","text":"<p>A thin wrapper around xarray for reading and writing Ensemble Forecast Time Series (EFTS) data sets.</p>"},{"location":"reference/efts_io/wrapper/#efts_io.wrapper.EftsDataSet","title":"EftsDataSet","text":"<pre><code>EftsDataSet(data: Union[str, Dataset])\n</code></pre> <p>Convenience class for access to a Ensemble Forecast Time Series in netCDF file.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def __init__(self, data: Union[str, xr.Dataset]) -&gt; None:\n    \"\"\"Create a new EftsDataSet object.\"\"\"\n    from xarray.coding import times\n\n    self.time_dim = None\n    self.time_zone = \"UTC\"\n    self.time_zone_timestamps = True  # Not sure about https://github.com/csiro-hydroinformatics/efts-io/issues/3\n    self.STATION_DIMNAME = STATION_DIMNAME\n    self.stations_varname = STATION_ID_VARNAME\n    self.LEAD_TIME_DIMNAME = LEAD_TIME_DIMNAME\n    self.ENS_MEMBER_DIMNAME = ENS_MEMBER_DIMNAME\n    self.identifiers_dimensions = []\n    if isinstance(data, str):\n        # work around https://jira.csiro.au/browse/WIRADA-635\n        # lead_time can be a problem with xarray, so do not decode \"times\"\n        x = xr.open_dataset(data, decode_times=False)\n\n        # replace the time and station names coordinates values\n        # TODO This is probably not a long term solution for round-tripping a read/write or vice and versa\n        decod = times.CFDatetimeCoder(use_cftime=True)\n        var = xr.as_variable(x.coords[TIME_DIMNAME])\n        self.time_zone = var.attrs[TIME_STANDARD_ATTR_KEY]\n        time_coords = decod.decode(var, name=TIME_DIMNAME)\n        tz = self.time_zone if self.time_zone_timestamps else None\n        time_coords.values = cftimes_to_pdtstamps(\n            time_coords.values,\n            tz_str=tz,\n        )\n        # stat_coords = x.coords[self.STATION_DIMNAME]\n        station_names = byte_stations_to_str(x[STATION_NAME_VARNAME].values)\n        x = x.assign_coords(\n            {TIME_DIMNAME: time_coords, self.STATION_DIMNAME: station_names},\n        )\n\n        self.data: xr.Dataset = x\n    else:\n        self.data: xr.Dataset = data\n</code></pre>"},{"location":"reference/efts_io/wrapper/#efts_io.wrapper.EftsDataSet.create_data_variables","title":"create_data_variables","text":"<pre><code>create_data_variables(\n    data_var_def: Dict[str, Dict[str, Any]]\n) -&gt; None\n</code></pre> <p>Create data variables in the data set.</p> <p>var_defs_dict[\"variable_1\"].keys() dict_keys(['name', 'longname', 'units', 'dim_type', 'missval', 'precision', 'attributes'])</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def create_data_variables(self, data_var_def: Dict[str, Dict[str, Any]]) -&gt; None:\n    \"\"\"Create data variables in the data set.\n\n    var_defs_dict[\"variable_1\"].keys()\n    dict_keys(['name', 'longname', 'units', 'dim_type', 'missval', 'precision', 'attributes'])\n    \"\"\"\n    ens_fcast_data_var_def = [x for x in data_var_def.values() if x[\"dim_type\"] == \"4\"]\n    ens_data_var_def = [x for x in data_var_def.values() if x[\"dim_type\"] == \"3\"]\n    point_data_var_def = [x for x in data_var_def.values() if x[\"dim_type\"] == \"2\"]\n\n    four_dims_names = (LEAD_TIME_DIMNAME, STATION_DIMNAME, ENS_MEMBER_DIMNAME, TIME_DIMNAME)\n    three_dims_names = (STATION_DIMNAME, ENS_MEMBER_DIMNAME, TIME_DIMNAME)\n    two_dims_names = (STATION_DIMNAME, TIME_DIMNAME)\n\n    four_dims_shape = tuple(self.data.sizes[dimname] for dimname in four_dims_names)\n    three_dims_shape = tuple(self.data.sizes[dimname] for dimname in three_dims_names)\n    two_dims_shape = tuple(self.data.sizes[dimname] for dimname in two_dims_names)\n    for vardefs, dims_shape, dims_names in [\n        (ens_fcast_data_var_def, four_dims_shape, four_dims_names),\n        (ens_data_var_def, three_dims_shape, three_dims_names),\n        (point_data_var_def, two_dims_shape, two_dims_names),\n    ]:\n        for x in vardefs:\n            varname = x[\"name\"]\n            self.data[varname] = xr.DataArray(\n                name=varname,\n                data=nan_full(dims_shape),\n                coords=self.data.coords,\n                dims=dims_names,\n                attrs={\n                    \"longname\": x[\"longname\"],\n                    UNITS_ATTR_KEY: x[UNITS_ATTR_KEY],\n                    \"missval\": x[\"missval\"],\n                    \"precision\": x[\"precision\"],\n                    **x[\"attributes\"],\n                },\n            )\n</code></pre>"},{"location":"reference/efts_io/wrapper/#efts_io.wrapper.EftsDataSet.get_all_series","title":"get_all_series","text":"<pre><code>get_all_series(\n    variable_name: str = \"rain_obs\",\n    dimension_id: Optional[str] = None,\n)\n</code></pre> <p>Return a multivariate time series, where each column is the series for one of the identifiers.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def get_all_series(\n    self,\n    variable_name: str = \"rain_obs\",\n    dimension_id: Optional[str] = None,\n):\n    \"\"\"Return a multivariate time series, where each column is the series for one of the identifiers.\"\"\"\n    # Return a multivariate time series, where each column is the series for one of the identifiers (self, e.g. rainfall station identifiers):\n    return self.data[variable_name]\n</code></pre>"},{"location":"reference/efts_io/wrapper/#efts_io.wrapper.EftsDataSet.get_dim_names","title":"get_dim_names","text":"<pre><code>get_dim_names() -&gt; List[str]\n</code></pre> <p>Gets the name of all dimensions in the data set.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def get_dim_names(self) -&gt; List[str]:\n    \"\"\"Gets the name of all dimensions in the data set.\"\"\"\n    return list(self.data.dims.keys())\n</code></pre>"},{"location":"reference/efts_io/wrapper/#efts_io.wrapper.EftsDataSet.get_ensemble_for_stations","title":"get_ensemble_for_stations","text":"<pre><code>get_ensemble_for_stations(\n    variable_name: str = \"rain_sim\",\n    identifier: Optional[str] = None,\n    dimension_id: str = ENS_MEMBER_DIMNAME,\n    start_time: Timestamp = None,\n    lead_time_count: Optional[int] = None,\n) -&gt; DataArray\n</code></pre> <p>Not yet implemented.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def get_ensemble_for_stations(\n    self,\n    variable_name: str = \"rain_sim\",\n    identifier: Optional[str] = None,\n    dimension_id: str = ENS_MEMBER_DIMNAME,\n    start_time: pd.Timestamp = None,\n    lead_time_count: Optional[int] = None,\n) -&gt; xr.DataArray:\n    \"\"\"Not yet implemented.\"\"\"\n    # Return a time series, representing a single ensemble member forecast for all stations over the lead time\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/efts_io/wrapper/#efts_io.wrapper.EftsDataSet.get_ensemble_forecasts","title":"get_ensemble_forecasts","text":"<pre><code>get_ensemble_forecasts(\n    variable_name: str = \"rain_sim\",\n    identifier: Optional[str] = None,\n    dimension_id: Optional[str] = None,\n    start_time: Optional[Timestamp] = None,\n    lead_time_count: Optional[int] = None,\n) -&gt; DataArray\n</code></pre> <p>Gets an ensemble forecast for a variable.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def get_ensemble_forecasts(\n    self,\n    variable_name: str = \"rain_sim\",\n    identifier: Optional[str] = None,\n    dimension_id: Optional[str] = None,\n    start_time: Optional[pd.Timestamp] = None,\n    lead_time_count: Optional[int] = None,\n) -&gt; xr.DataArray:\n    \"\"\"Gets an ensemble forecast for a variable.\"\"\"\n    # Return a time series, ensemble of forecasts over the lead time\n    if dimension_id is None:\n        dimension_id = self.get_stations_varname()\n    td = self.get_time_dim()\n    if start_time is None:\n        start_time = td[0]\n    n_ens = self.get_ensemble_size()\n    index_id = self.index_for_identifier(identifier, dimension_id)\n    check_index_found(index_id, identifier, dimension_id)\n    if lead_time_count is None:\n        lead_time_count = self.get_lead_time_count()\n    indx_time = self.index_for_time(start_time)\n    # float rain_sim[lead_time,station,ens_member,time]\n    ens_data = self.data.get(variable_name)[\n        indx_time,\n        :n_ens,\n        index_id,\n        :lead_time_count,\n    ]\n    # ensData = self.data.get(variable_name), start = [1, index_id, 1, indTime],\n    #     count = c(lead_time_count, 1, nEns, 1), collapse_degen = FALSE)\n    # tu = self.get_lead_time_unit()\n    # if tu == \"days\":\n    #     timeAxis = start_time + pd.Timedelta(ncfile$dim$lead_time$vals)\n    # } else {\n    # timeAxis = start_time + lubridate::dhours(1) * ncfile$dim$lead_time$vals\n    # }\n    # out = xts(x = ensData[, 1, , 1], order.by = timeAxis, tzone = tz(start_time))\n    return ens_data\n</code></pre>"},{"location":"reference/efts_io/wrapper/#efts_io.wrapper.EftsDataSet.get_ensemble_forecasts_for_station","title":"get_ensemble_forecasts_for_station","text":"<pre><code>get_ensemble_forecasts_for_station(\n    variable_name: str = \"rain_sim\",\n    identifier: Optional[str] = None,\n    dimension_id: Optional[str] = None,\n)\n</code></pre> <p>Return an array, representing all ensemble member forecasts for a single stations over all lead times.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def get_ensemble_forecasts_for_station(\n    self,\n    variable_name: str = \"rain_sim\",\n    identifier: Optional[str] = None,\n    dimension_id: Optional[str] = None,\n):\n    \"\"\"Return an array, representing all ensemble member forecasts for a single stations over all lead times.\"\"\"\n    # Return an array, representing all ensemble member forecasts for a single stations over all lead times\n    if dimension_id is None:\n        dimension_id = self.get_stations_varname()\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/efts_io/wrapper/#efts_io.wrapper.EftsDataSet.get_ensemble_series","title":"get_ensemble_series","text":"<pre><code>get_ensemble_series(\n    variable_name: str = \"rain_ens\",\n    identifier: Optional[str] = None,\n    dimension_id: Optional[str] = None,\n)\n</code></pre> <p>Return an ensemble of point time series for a station identifier.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def get_ensemble_series(\n    self,\n    variable_name: str = \"rain_ens\",\n    identifier: Optional[str] = None,\n    dimension_id: Optional[str] = None,\n):\n    \"\"\"Return an ensemble of point time series for a station identifier.\"\"\"\n    # Return an ensemble of point time series for a station identifier\n    if dimension_id is None:\n        dimension_id = self.get_stations_varname()\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/efts_io/wrapper/#efts_io.wrapper.EftsDataSet.get_ensemble_size","title":"get_ensemble_size","text":"<pre><code>get_ensemble_size()\n</code></pre> <p>Return the length of the ensemble size dimension.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def get_ensemble_size(self):\n    \"\"\"Return the length of the ensemble size dimension.\"\"\"\n    return self.data.dims[self.ENS_MEMBER_DIMNAME]\n</code></pre>"},{"location":"reference/efts_io/wrapper/#efts_io.wrapper.EftsDataSet.get_lead_time_count","title":"get_lead_time_count","text":"<pre><code>get_lead_time_count()\n</code></pre> <p>Length of the lead time dimension.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def get_lead_time_count(self):\n    \"\"\"Length of the lead time dimension.\"\"\"\n    return self.data.dims[self.LEAD_TIME_DIMNAME]\n</code></pre>"},{"location":"reference/efts_io/wrapper/#efts_io.wrapper.EftsDataSet.get_lead_time_values","title":"get_lead_time_values","text":"<pre><code>get_lead_time_values()\n</code></pre> <p>Return the values of the lead time dimension.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def get_lead_time_values(self):\n    \"\"\"Return the values of the lead time dimension.\"\"\"\n    return self.data[self.LEAD_TIME_DIMNAME].values\n</code></pre>"},{"location":"reference/efts_io/wrapper/#efts_io.wrapper.EftsDataSet.get_single_series","title":"get_single_series","text":"<pre><code>get_single_series(\n    variable_name: str = \"rain_obs\",\n    identifier: Optional[str] = None,\n    dimension_id: Optional[str] = None,\n)\n</code></pre> <p>Return a single point time series for a station identifier.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def get_single_series(\n    self,\n    variable_name: str = \"rain_obs\",\n    identifier: Optional[str] = None,\n    dimension_id: Optional[str] = None,\n):\n    \"\"\"Return a single point time series for a station identifier.\"\"\"\n    # Return a single point time series for a station identifier. Falls back on def get_all_series if the argument \"identifier\" is missing\n    if dimension_id is None:\n        dimension_id = self.get_stations_varname()\n    return self.data[variable_name].sel({dimension_id: identifier})\n</code></pre>"},{"location":"reference/efts_io/wrapper/#efts_io.wrapper.EftsDataSet.get_station_count","title":"get_station_count","text":"<pre><code>get_station_count() -&gt; int\n</code></pre> <p>Return the number of stations in the data set.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def get_station_count(self) -&gt; int:\n    \"\"\"Return the number of stations in the data set.\"\"\"\n    self.data.dims[self.STATION_DIMNAME]\n</code></pre>"},{"location":"reference/efts_io/wrapper/#efts_io.wrapper.EftsDataSet.get_stations_varname","title":"get_stations_varname","text":"<pre><code>get_stations_varname() -&gt; str\n</code></pre> <p>Return the name of the variable that has the station identifiers.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def get_stations_varname(self) -&gt; str:\n    \"\"\"Return the name of the variable that has the station identifiers.\"\"\"\n    # Gets the name of the variable that has the station identifiers\n    # TODO: station is integer normally in STF (Euargh)\n    return STATION_ID_VARNAME\n</code></pre>"},{"location":"reference/efts_io/wrapper/#efts_io.wrapper.EftsDataSet.get_time_dim","title":"get_time_dim","text":"<pre><code>get_time_dim()\n</code></pre> <p>Return the time dimension variable as a vector of date-time stamps.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def get_time_dim(self):\n    \"\"\"Return the time dimension variable as a vector of date-time stamps.\"\"\"\n    # Gets the time dimension variable as a vector of date-time stamps\n    return self.data.time.values  # but loosing attributes.\n</code></pre>"},{"location":"reference/efts_io/wrapper/#efts_io.wrapper.EftsDataSet.get_time_unit","title":"get_time_unit","text":"<pre><code>get_time_unit()\n</code></pre> <p>Return the time units of a read time series.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def get_time_unit(self):\n    \"\"\"Return the time units of a read time series.\"\"\"\n    # Gets the time units of a read time series, i.e. \"hours since 2015-10-04 00:00:00 +1030\". Returns the string \"hours\"\n    return \"dummy\"\n</code></pre>"},{"location":"reference/efts_io/wrapper/#efts_io.wrapper.EftsDataSet.put_lead_time_values","title":"put_lead_time_values","text":"<pre><code>put_lead_time_values(values)\n</code></pre> <p>Set the values of the lead time dimension.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def put_lead_time_values(self, values):\n    \"\"\"Set the values of the lead time dimension.\"\"\"\n    self.data[self.LEAD_TIME_DIMNAME].values = values\n</code></pre>"},{"location":"reference/efts_io/wrapper/#efts_io.wrapper.EftsDataSet.to_netcdf","title":"to_netcdf","text":"<pre><code>to_netcdf(path: str, version: str = '2.0') -&gt; None\n</code></pre> <p>Write the data set to a netCDF file.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def to_netcdf(self, path: str, version: str = \"2.0\") -&gt; None:\n    \"\"\"Write the data set to a netCDF file.\"\"\"\n    if version != \"2.0\":\n        raise ValueError(\"Only version 2.0 is supported for now\")\n    self.data.to_netcdf(path)\n</code></pre>"},{"location":"reference/efts_io/wrapper/#efts_io.wrapper.byte_to_string","title":"byte_to_string","text":"<pre><code>byte_to_string(x: Union[int, bytes]) -&gt; str\n</code></pre> <p>Convert a byte to a string.</p> Source code in <code>src/efts_io/wrapper.py</code> <pre><code>def byte_to_string(x: Union[int, bytes]) -&gt; str:\n    \"\"\"Convert a byte to a string.\"\"\"\n    if isinstance(x, int):\n        if x &gt; 255 or x &lt; 0:\n            raise ValueError(\"Integer value to bytes: must be in range [0-255]\")\n        x = x.to_bytes(1, \"little\")\n    if not isinstance(x, bytes):\n        raise TypeError(f\"Cannot cast type {type(x)} to bytes\")\n    return str(x, encoding=\"UTF-8\")\n</code></pre>"},{"location":"coverage/","title":"Coverage report","text":""}]}